import streamlit as st
import pandas as pd
import requests
from io import BytesIO
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from plotly.subplots import make_subplots
from math import ceil
import hashlib
from streamlit import session_state

# ------------------------------
# æ–°å¢ï¼šç”¨æˆ·è®¤è¯ä¸æƒé™ç®¡ç†
# ------------------------------
def check_credentials():
    """éªŒè¯ç”¨æˆ·å¯†ç å¹¶è¿”å›ç”¨æˆ·æƒé™ï¼ˆè´Ÿè´£çš„åº—é“ºï¼‰ï¼Œç”¨æˆ·åæ”¹ä¸ºä¸‹æ‹‰æ¡†é€‰æ‹©"""
    # ç”¨æˆ·-å¯†ç -æƒé™æ˜ å°„ï¼ˆå»ºè®®å®é™…ä½¿ç”¨æ—¶æ”¾åœ¨secretsä¸­ï¼‰
    USER_PERMISSIONS = {
        "é»„æ€¡": ("syc-huangyi123", ["æ€ä¸šæˆ-US"]),  # ç”¨æˆ·1èƒ½çœ‹çš„åº—é“º
        "æ³½æ’": ("dx-zeheng123", ["å®šè¡Œ-US"]),  # ç”¨æˆ·2èƒ½çœ‹çš„åº—é“º
        "å°å¨‡": ("pt and ys-xiaojiao", ["æ‹¼é€”-US","è‰ºèƒœ-US"]),  # ç”¨æˆ·3èƒ½çœ‹çš„åº—é“º
        "æ¥·çº¯": ("zy and cr-kaichun", ["äº‰è‰³-US","è¾°ç‘-US"]),  # ç”¨æˆ·4èƒ½çœ‹çš„åº—é“º
        "æ·‘è°Š": ("sx and jy-shuyi", ["åŠ¿å…´-US","è¿›ç›Š-US"]),  # ç”¨æˆ·5èƒ½çœ‹çš„åº—é“º
        "ä½°è‹±": ("cq-baiying123", ["åˆ›å¥‡-US"]),  # ç”¨æˆ·6èƒ½çœ‹çš„åº—é“º
        "æçŠ": ("dm-lishan123", ["å¤§å–-US"]),  # ç”¨æˆ·7èƒ½çœ‹çš„åº—é“º
        "admin": ("admin1234", None)  # ç®¡ç†å‘˜èƒ½çœ‹æ‰€æœ‰åº—é“º
    }

    # è·å–æ‰€æœ‰ç”¨æˆ·åä½œä¸ºä¸‹æ‹‰é€‰é¡¹
    all_users = list(USER_PERMISSIONS.keys())

    def verify():
        # ä»ä¼šè¯çŠ¶æ€è·å–é€‰æ‹©çš„ç”¨æˆ·åå’Œè¾“å…¥çš„å¯†ç 
        username = st.session_state.get("selected_user", "")
        password = st.session_state.get("password", "")

        if username in USER_PERMISSIONS:
            stored_pwd, stores = USER_PERMISSIONS[username]
            if password == stored_pwd:
                st.session_state["authenticated"] = True
                st.session_state["allowed_stores"] = stores  # ä¿å­˜ç”¨æˆ·å¯è®¿é—®çš„åº—é“º
                del st.session_state["password"]  # æ¸…é™¤å¯†ç 
            else:
                st.session_state["authenticated"] = False
        else:
            st.session_state["authenticated"] = False

    # æœªè®¤è¯çŠ¶æ€ï¼šæ˜¾ç¤ºç™»å½•è¡¨å•ï¼ˆä¸‹æ‹‰æ¡†é€‰æ‹©ç”¨æˆ·åï¼‰
    if "authenticated" not in st.session_state or not st.session_state["authenticated"]:
        st.title("ç”¨æˆ·ç™»å½•")

        # ç”¨æˆ·åä¸‹æ‹‰æ¡†ï¼ˆè€Œéè¾“å…¥æ¡†ï¼‰
        st.selectbox(
            "è¯·é€‰æ‹©ç”¨æˆ·å",
            options=all_users,
            key="selected_user",
            on_change=verify  # é€‰æ‹©å˜åŒ–æ—¶è§¦å‘éªŒè¯
        )

        # å¯†ç è¾“å…¥æ¡†
        st.text_input(
            "è¯·è¾“å…¥å¯†ç ",
            type="password",
            key="password",
            on_change=verify  # è¾“å…¥å¯†ç æ—¶è§¦å‘éªŒè¯
        )

        # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if "authenticated" in st.session_state and not st.session_state["authenticated"]:
            st.error("å¯†ç é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥")
        return False
    return True


# éªŒè¯ä¸é€šè¿‡åˆ™ç»ˆæ­¢
if not check_credentials():
    st.stop()

# å…¨å±€é…ç½®
st.set_page_config(page_title="å¹´ä»½å“æ»é”€é£é™©åˆ†æä»ªè¡¨ç›˜", layout="wide", initial_sidebar_state="expanded")
st.markdown("""
<style>
    .dataframe th {font-size: 14px; text-align: center;}
    .dataframe td {font-size: 13px; text-align: center;}
    .metric-card {background-color: #f8f9fa; padding: 15px; border-radius: 8px; text-align: center; margin-bottom: 15px;}
    .metric-title {font-size: 15px; color: #666; margin-bottom: 5px;}
    .metric-value {font-size: 24px; font-weight: bold;}
    .metric-change {font-size: 14px;}
    .positive-change {color: #2E8B57;}
    .negative-change {color: #DC143C;}
    .neutral-change {color: #000000;}
    /* å›ºå®šä¾§è¾¹æ ä¸æ»šåŠ¨ */
    [data-testid="stSidebar"] {
        position: fixed;
        height: 100%;
        overflow: auto;
    }
</style>
""", unsafe_allow_html=True)

# é¢œè‰²é…ç½®
STATUS_COLORS = {
    "å¥åº·": "#2E8B57",  # ç»¿è‰²
    "ä½æ»é”€é£é™©": "#4169E1",  # è“è‰²
    "ä¸­æ»é”€é£é™©": "#FFD700",  # é»„è‰²
    "é«˜æ»é”€é£é™©": "#DC143C"  # çº¢è‰²
}
TARGET_DATE = datetime(2025, 12, 1)  # ç›®æ ‡æ¶ˆè€—å®Œæˆæ—¥æœŸ
END_DATE = datetime(2025, 12, 31)  # é¢„æµ‹æˆªæ­¢æ—¥æœŸ


# ------------------------------
# 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†å‡½æ•°
# ------------------------------
# ------------------------------
# å…¨å±€é…ç½®ï¼ˆç‹¬ç«‹äºå‡½æ•°ï¼Œä¾¿äºç»´æŠ¤ï¼‰
# ------------------------------
# 1. é»˜è®¤ç³»æ•°é…ç½®ï¼ˆè¿è¥æœªç¼–è¾‘æ—¶ä½¿ç”¨ï¼‰
DEFAULT_COEFFICIENTS = {
    "10æœˆ15-31æ—¥ç³»æ•°": 0.95,
    "11æœˆ1-15æ—¥ç³»æ•°": 0.91,
    "11æœˆ16-30æ—¥ç³»æ•°": 0.72,
    "12æœˆ1-31æ—¥ç³»æ•°": 0.43
}

# 2. æ—¶é—´æ®µä¸ç³»æ•°åˆ—çš„æ˜ å°„ï¼ˆå…³è”è®¡ç®—é€»è¾‘å’Œç¼–è¾‘åçš„ç³»æ•°åˆ—ï¼‰
PERIOD_COEFF_MAP = [
    {"start": datetime(2025, 10, 15), "end": datetime(2025, 10, 31), "coeff_col": "10æœˆ15-31æ—¥ç³»æ•°"},
    {"start": datetime(2025, 11, 1), "end": datetime(2025, 11, 15), "coeff_col": "11æœˆ1-15æ—¥ç³»æ•°"},
    {"start": datetime(2025, 11, 16), "end": datetime(2025, 11, 30), "coeff_col": "11æœˆ16-30æ—¥ç³»æ•°"},
    {"start": datetime(2025, 12, 1), "end": datetime(2025, 12, 31), "coeff_col": "12æœˆ1-31æ—¥ç³»æ•°"}
]
def render_coefficient_editor(original_df):
    """æ¸²æŸ“ç³»æ•°ç¼–è¾‘è¡¨æ ¼ï¼Œæ”¯æŒä¸‹è½½ã€ä¸Šä¼ ã€ç¡®è®¤åŠŸèƒ½"""
    st.subheader("ç³»æ•°ä¸æ—¥å‡è°ƒæ•´")
    st.info("åœ¨æ­¤ç¼–è¾‘äº§å“çš„æ—¥å‡å’Œæ—¶é—´æ®µç³»æ•°ï¼Œç¡®è®¤åçœ‹æ¿å°†ä½¿ç”¨æ–°æ•°æ®é‡æ–°è®¡ç®—")

    # 1. ç­›é€‰éœ€è¦ç¼–è¾‘çš„åˆ—ï¼ˆæŒ‰æ‚¨æŒ‡å®šçš„å­—æ®µï¼‰
    edit_cols = [
        "åº—é“º", "è®°å½•æ—¶é—´", "MSKU", "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
        "10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"
    ]

    # 2. åˆå§‹åŒ–ç¼–è¾‘æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨å·²ä¸Šä¼ çš„æ•°æ®ï¼Œå¦åˆ™ç”¨åŸå§‹æ•°æ®ï¼‰
    if "edited_df" in st.session_state:
        edit_data = st.session_state.edited_df[edit_cols].copy()
    else:
        # ä»åŸå§‹æ•°æ®ä¸­æå–ç¼–è¾‘åˆ—ï¼Œå»é‡ï¼ˆæŒ‰MSKUå’Œè®°å½•æ—¶é—´ï¼‰
        edit_data = original_df[edit_cols].drop_duplicates(subset=["MSKU", "è®°å½•æ—¶é—´"]).copy()
        # ç¡®ä¿ç³»æ•°åˆ—æ˜¯æ•°å€¼ç±»å‹
        coeff_cols = ["10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"]
        for col in coeff_cols:
            edit_data[col] = edit_data[col].astype(float)

    # 3. æ˜¾ç¤ºå¯ç¼–è¾‘è¡¨æ ¼ï¼ˆä½¿ç”¨st.data_editorï¼‰
    edited_data = st.data_editor(
        edit_data,
        num_rows="dynamic",  # å…è®¸å¢åˆ è¡Œ
        column_config={
            # é…ç½®ç³»æ•°åˆ—çš„ç¼–è¾‘èŒƒå›´ï¼ˆ0-2ä¹‹é—´ï¼Œæ­¥é•¿0.01ï¼‰
            "10æœˆ15-31æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01),
            "11æœˆ1-15æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01),
            "11æœˆ16-30æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01),
            "12æœˆ1-31æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01),
            # é…ç½®æ—¥å‡åˆ—ï¼ˆéè´Ÿï¼‰
            "æ—¥å‡": st.column_config.NumberColumn(min_value=0),
            "7å¤©æ—¥å‡": st.column_config.NumberColumn(min_value=0),
            "14å¤©æ—¥å‡": st.column_config.NumberColumn(min_value=0),
            "28å¤©æ—¥å‡": st.column_config.NumberColumn(min_value=0),
        },
        key="coefficient_editor"
    )

    # 4. ä¸‹è½½åŠŸèƒ½ï¼ˆä¸‹è½½å½“å‰ç¼–è¾‘çš„è¡¨æ ¼ï¼‰
    csv = edited_data.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        "ğŸ’¾ ä¸‹è½½å½“å‰è¡¨æ ¼",
        data=csv,
        file_name="ç³»æ•°è°ƒæ•´è¡¨æ ¼.csv",
        mime="text/csv"
    )

    # 5. ä¸Šä¼ åŠŸèƒ½ï¼ˆä¸Šä¼ ä¿®æ”¹åçš„è¡¨æ ¼ï¼‰
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼ ä¿®æ”¹åçš„è¡¨æ ¼", type=["csv", "xlsx"])
    if uploaded_file:
        try:
            if uploaded_file.name.endswith(".csv"):
                # å¤šç¼–ç å°è¯•
                try:
                    uploaded_df = pd.read_csv(uploaded_file, encoding="gbk")
                except:
                    uploaded_df = pd.read_csv(uploaded_file, encoding="utf-8")
            else:
                uploaded_df = pd.read_excel(uploaded_file, engine="openpyxl")

            # æ ¡éªŒä¸Šä¼ çš„åˆ—æ˜¯å¦ç¬¦åˆè¦æ±‚
            missing_cols = [col for col in edit_cols if col not in uploaded_df.columns]
            if missing_cols:
                st.error(f"ä¸Šä¼ çš„è¡¨æ ¼ç¼ºå°‘å¿…è¦åˆ—ï¼š{', '.join(missing_cols)}")
            else:
                # æ ¼å¼è½¬æ¢
                if "è®°å½•æ—¶é—´" in uploaded_df.columns:
                    uploaded_df["è®°å½•æ—¶é—´"] = pd.to_datetime(uploaded_df["è®°å½•æ—¶é—´"], errors="coerce").dt.normalize()
                numeric_edit_cols = ["æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                                     "10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"]
                for col in numeric_edit_cols:
                    if col in uploaded_df.columns:
                        uploaded_df[col] = pd.to_numeric(uploaded_df[col], errors="coerce").fillna(0)

                st.success("è¡¨æ ¼ä¸Šä¼ æˆåŠŸï¼Œå·²æ›´æ–°ç¼–è¾‘åŒºæ•°æ®")
                edited_data = uploaded_df[edit_cols].copy()
                # å…³é”®ä¿®æ”¹ï¼šä¸Šä¼ æˆåŠŸåç«‹å³æ›´æ–°session_state
                st.session_state.edited_df = edited_data  # æ–°å¢è¿™ä¸€è¡Œ
        except Exception as e:
            st.error(f"ä¸Šä¼ å¤±è´¥ï¼š{str(e)}")

    # 6. ç¡®è®¤æŒ‰é’®ï¼ˆä¿å­˜ç¼–è¾‘åçš„æ•°æ®ï¼Œè§¦å‘é‡æ–°è®¡ç®—ï¼‰
    if st.button("âœ… ç¡®è®¤å¹¶åº”ç”¨ä¿®æ”¹"):
        # ä¿å­˜ç¼–è¾‘åçš„æ•°æ®åˆ°session_state
        st.session_state.edited_df = edited_data
        # æ ‡è®°éœ€è¦é‡æ–°è®¡ç®—
        st.session_state.needs_recalculation = True
        st.success("ä¿®æ”¹å·²ä¿å­˜ï¼Œçœ‹æ¿å°†ä½¿ç”¨æ–°æ•°æ®é‡æ–°è®¡ç®—")
        st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ï¼ŒåŠ è½½æ–°æ•°æ®

# ------------------------------
# æ ¸å¿ƒæ•°æ®å¤„ç†å‡½æ•°ï¼ˆæ”¯æŒè¿è¥ç¼–è¾‘ï¼‰
# ------------------------------
@st.cache_data(ttl=3600)  # ç§»é™¤key_funcå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤ç¼“å­˜é€»è¾‘
def load_and_preprocess_data_from_df(df):
    """åŠ è½½Excelæ•°æ®å¹¶è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…å«æ‰€æœ‰åˆ—çš„è®¡ç®—é€»è¾‘ï¼ˆæ”¯æŒè¿è¥ç¼–è¾‘æ—¥å‡/ç³»æ•°ï¼‰"""
    try:
        # 1. åŸºç¡€åˆ—æ£€æŸ¥ä¸æ•°æ®ç±»å‹è½¬æ¢ï¼ˆä¿ç•™åŸé€»è¾‘ï¼Œå¢å¼ºå…¼å®¹æ€§ï¼‰
        required_base_cols = [
            "MSKU", "å“å", "åº—é“º", "è®°å½•æ—¶é—´", "æ—¥å‡",
            "FBAåº“å­˜", "FBAåœ¨é€”", "æµ·å¤–ä»“åœ¨é€”", "æœ¬åœ°å¯ç”¨",
            "å¾…æ£€å¾…ä¸Šæ¶é‡", "å¾…äº¤ä»˜"
        ]
        missing_cols = [col for col in required_base_cols if col not in df.columns]
        if missing_cols:
            st.error(f"Excelæ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åŸºç¡€åˆ—ï¼š{', '.join(missing_cols)}")
            return None

        # æ—¥æœŸåˆ—æ ‡å‡†åŒ–
        df["è®°å½•æ—¶é—´"] = pd.to_datetime(df["è®°å½•æ—¶é—´"]).dt.normalize()
        # æ•°å€¼åˆ—è½¬æ¢ï¼ˆæ–°å¢7/14/28å¤©æ—¥å‡æ”¯æŒï¼Œé€‚é…è¿è¥ç¼–è¾‘ï¼‰
        numeric_cols = [
            "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
            "FBAåº“å­˜", "FBAåœ¨é€”", "æµ·å¤–ä»“åœ¨é€”",
            "æœ¬åœ°å¯ç”¨", "å¾…æ£€å¾…ä¸Šæ¶é‡", "å¾…äº¤ä»˜"
        ]
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)
            else:
                df[col] = 0  # æ— æ­¤åˆ—æ—¶å¡«å……é»˜è®¤å€¼ï¼Œé¿å…è®¡ç®—æŠ¥é”™

        # ------------------------------
        # 2. ç”Ÿæˆç³»æ•°åˆ—å’Œè°ƒæ•´åæ—¥å‡åˆ—ï¼ˆæ”¯æŒè¿è¥ç¼–è¾‘è¦†ç›–ï¼‰
        # ------------------------------
        # 2.1 ç³»æ•°åˆ—ï¼šä¼˜å…ˆä¿ç•™dfä¸­å·²æœ‰çš„å€¼ï¼ˆè¿è¥ç¼–è¾‘åçš„æ•°æ®ï¼‰ï¼Œæ— åˆ™ç”¨é»˜è®¤ç³»æ•°
        for coeff_col, default_val in DEFAULT_COEFFICIENTS.items():
            if coeff_col not in df.columns:
                df[coeff_col] = default_val  # åˆå§‹æ— æ•°æ®æ—¶ç”¨é»˜è®¤å€¼
            # ç¡®ä¿ç³»æ•°åˆ—ä¸ºæ•°å€¼ç±»å‹ï¼Œé¿å…ç¼–è¾‘åæ ¼å¼é”™è¯¯
            df[coeff_col] = pd.to_numeric(df[coeff_col], errors="coerce").fillna(default_val)

        # 2.2 è°ƒæ•´åæ—¥å‡åˆ—ï¼šåŸºäºè¿è¥ç¼–è¾‘åçš„ç³»æ•°è®¡ç®—ï¼ˆåŠ¨æ€æ›´æ–°ï¼‰
        df["10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡"] = (df["æ—¥å‡"] * df["10æœˆ15-31æ—¥ç³»æ•°"]).round(2)
        df["11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡"] = (df["æ—¥å‡"] * df["11æœˆ1-15æ—¥ç³»æ•°"]).round(2)
        df["11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡"] = (df["æ—¥å‡"] * df["11æœˆ16-30æ—¥ç³»æ•°"]).round(2)
        df["12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡"] = (df["æ—¥å‡"] * df["12æœˆ1-31æ—¥ç³»æ•°"]).round(2)

        # ------------------------------
        # 3. æ ¸å¿ƒè®¡ç®—é€»è¾‘ï¼ˆåŸºäºè¿è¥ç¼–è¾‘åçš„æ•°æ®ï¼‰
        # ------------------------------
        # 3.1 FBA+AWD+åœ¨é€”åº“å­˜ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        df["FBA+AWD+åœ¨é€”åº“å­˜"] = (df["FBAåº“å­˜"] + df["FBAåœ¨é€”"] + df["æµ·å¤–ä»“åœ¨é€”"]).round().astype(int)

        # 3.2 å…¨éƒ¨æ€»åº“å­˜ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        df["å…¨éƒ¨æ€»åº“å­˜"] = (
            df["FBA+AWD+åœ¨é€”åº“å­˜"] + df["æœ¬åœ°å¯ç”¨"] + df["å¾…æ£€å¾…ä¸Šæ¶é‡"] + df["å¾…äº¤ä»˜"]
        ).round().astype(int)

        # 3.3 åˆ†é˜¶æ®µè®¡ç®—åº“å­˜è€—å°½æ—¥æœŸï¼ˆæ ¸å¿ƒï¼šè¯»å–è¿è¥ç¼–è¾‘çš„ç³»æ•°ï¼‰
        def calculate_exhaust_date(row, stock_col):
            record_date = row["è®°å½•æ—¶é—´"]
            stock = row[stock_col]
            base_avg = row["æ—¥å‡"] if row["æ—¥å‡"] > 0 else 0.1  # ä¼˜å…ˆç”¨è¿è¥ç¼–è¾‘çš„æ—¥å‡
            remaining_stock = stock
            current_date = record_date

            # åº“å­˜ä¸º0æ—¶ç›´æ¥è¿”å›
            if remaining_stock <= 0:
                return record_date

            # é˜¶æ®µ1ï¼šè®°å½•æ—¥æœŸ â†’ 2025-10-14ï¼ˆç³»æ•°=1.0ï¼Œæ— è°ƒæ•´ï¼‰
            phase1_end = datetime(2025, 10, 14)
            if current_date <= phase1_end:
                days_in_phase = (phase1_end - current_date).days + 1  # åŒ…å«é¦–å°¾æ—¥æœŸ
                sales_possible = base_avg * days_in_phase
                if remaining_stock <= sales_possible:
                    days_needed = remaining_stock / base_avg
                    return current_date + pd.Timedelta(days=days_needed)
                remaining_stock -= sales_possible
                current_date = phase1_end + pd.Timedelta(days=1)

            # é˜¶æ®µ2ï¼šå¤„ç†4ä¸ªç‰¹æ®Šæ—¶é—´æ®µï¼ˆä½¿ç”¨è¿è¥ç¼–è¾‘çš„ç³»æ•°ï¼‰
            for period in PERIOD_COEFF_MAP:
                if current_date > period["end"] or remaining_stock <= 0:
                    break
                period_start = max(current_date, period["start"])
                if period_start > period["end"]:
                    continue
                days_in_period = (period["end"] - period_start).days + 1
                # å…³é”®ï¼šè¯»å–è¿è¥ç¼–è¾‘åçš„ç³»æ•°ï¼ˆæ— åˆ™ç”¨é»˜è®¤ï¼‰
                coeff = row[period["coeff_col"]] if period["coeff_col"] in row else DEFAULT_COEFFICIENTS[period["coeff_col"]]
                adjusted_avg = base_avg * coeff  # åº”ç”¨åŠ¨æ€ç³»æ•°
                sales_possible = adjusted_avg * days_in_period
                if remaining_stock <= sales_possible:
                    days_needed = remaining_stock / adjusted_avg
                    return period_start + pd.Timedelta(days=days_needed)
                remaining_stock -= sales_possible
                current_date = period["end"] + pd.Timedelta(days=1)

            # é˜¶æ®µ3ï¼š2026-01-01ä¹‹åï¼ˆç³»æ•°=1.0ï¼Œæ¢å¤åŸºç¡€æ—¥å‡ï¼‰
            if remaining_stock > 0:
                days_needed = remaining_stock / base_avg
                return current_date + pd.Timedelta(days=days_needed)
            return current_date

        # 3.4 é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´ï¼ˆè°ƒç”¨åˆ†é˜¶æ®µå‡½æ•°ï¼‰
        df["é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´"] = df.apply(
            lambda row: calculate_exhaust_date(row, "FBA+AWD+åœ¨é€”åº“å­˜"), axis=1
        )

        # 3.5 é¢„è®¡æ€»åº“å­˜ç”¨å®Œæ—¶é—´ï¼ˆè°ƒç”¨åˆ†é˜¶æ®µå‡½æ•°ï¼‰
        df["é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"] = df.apply(
            lambda row: calculate_exhaust_date(row, "å…¨éƒ¨æ€»åº“å­˜"), axis=1
        )

        # 3.6 åˆ†é˜¶æ®µè®¡ç®—æ»é”€åº“å­˜ï¼ˆæ ¸å¿ƒï¼šè¯»å–è¿è¥ç¼–è¾‘çš„ç³»æ•°ï¼‰
        def calculate_overstock(row, stock_col):
            record_date = row["è®°å½•æ—¶é—´"]
            stock = row[stock_col]
            base_avg = row["æ—¥å‡"] if row["æ—¥å‡"] > 0 else 0.1
            target_date = TARGET_DATE  # éœ€åœ¨å‡½æ•°å¤–å®šä¹‰ï¼ˆå¦‚datetime(2025,12,1)ï¼‰
            remaining_stock = stock
            current_date = record_date
            sold_by_target = 0  # ç›®æ ‡æ—¥æœŸå‰å¯å”®å‡ºåº“å­˜

            # æ— éœ€è®¡ç®—çš„åœºæ™¯
            if current_date >= target_date or remaining_stock <= 0:
                return 0

            # é˜¶æ®µ1ï¼šè®°å½•æ—¥æœŸ â†’ 2025-10-14ï¼ˆç³»æ•°=1.0ï¼‰
            phase1_end = datetime(2025, 10, 14)
            if current_date <= phase1_end:
                actual_end = min(phase1_end, target_date)
                days_in_phase = (actual_end - current_date).days + 1
                sales = base_avg * days_in_phase
                sales = min(sales, remaining_stock)
                sold_by_target += sales
                remaining_stock -= sales
                current_date = actual_end + pd.Timedelta(days=1)
                if current_date > target_date or remaining_stock <= 0:
                    return max(0, stock - sold_by_target)

            # é˜¶æ®µ2ï¼šå¤„ç†4ä¸ªç‰¹æ®Šæ—¶é—´æ®µï¼ˆä½¿ç”¨è¿è¥ç¼–è¾‘çš„ç³»æ•°ï¼‰
            for period in PERIOD_COEFF_MAP:
                if current_date >= target_date or remaining_stock <= 0:
                    break
                period_start = max(current_date, period["start"])
                period_end = min(period["end"], target_date)
                if period_start > period_end:
                    continue
                days_in_period = (period_end - period_start).days + 1
                # å…³é”®ï¼šè¯»å–è¿è¥ç¼–è¾‘åçš„ç³»æ•°
                coeff = row[period["coeff_col"]] if period["coeff_col"] in row else DEFAULT_COEFFICIENTS[period["coeff_col"]]
                adjusted_avg = base_avg * coeff
                sales = adjusted_avg * days_in_period
                sales = min(sales, remaining_stock)
                sold_by_target += sales
                remaining_stock -= sales
                current_date = period_end + pd.Timedelta(days=1)

            # æ»é”€åº“å­˜ = æ€»åº“å­˜ - ç›®æ ‡æ—¥æœŸå‰å¯å”®å‡ºåº“å­˜ï¼ˆéè´Ÿï¼‰
            return max(0, stock - sold_by_target)

        # 3.7 é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°ï¼ˆåŸºäºåŠ¨æ€è®¡ç®—ç»“æœï¼‰
        days_diff = (df["é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"] - TARGET_DATE).dt.days
        df["é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°"] = np.where(days_diff > 0, days_diff, 0).astype(int)

        # 3.8 çŠ¶æ€åˆ¤æ–­ï¼ˆé€»è¾‘ä¸å˜ï¼Œä¾èµ–åŠ¨æ€è®¡ç®—çš„å¤©æ•°ï¼‰
        def determine_status(days):
            if days >= 20:
                return "é«˜æ»é”€é£é™©"
            elif days >= 10:
                return "ä¸­æ»é”€é£é™©"
            elif days > 0:
                return "ä½æ»é”€é£é™©"
            else:
                return "å¥åº·"
        df["çŠ¶æ€åˆ¤æ–­"] = df["é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°"].apply(determine_status)

        # 3.9 ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        df = df.sort_values(["MSKU", "è®°å½•æ—¶é—´"])
        df["ä¸Šå‘¨çŠ¶æ€"] = df.groupby("MSKU")["çŠ¶æ€åˆ¤æ–­"].shift(1)
        status_severity = {"å¥åº·": 0, "ä½æ»é”€é£é™©": 1, "ä¸­æ»é”€é£é™©": 2, "é«˜æ»é”€é£é™©": 3}

        def compare_status(current, previous):
            if pd.isna(previous):
                return "-"
            if current == previous:
                return "ç»´æŒä¸å˜"
            current_sev = status_severity.get(current, 0)
            prev_sev = status_severity.get(previous, 0)
            return "æ”¹å–„" if current_sev < prev_sev else "æ¶åŒ–"

        df["ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"] = df.apply(
            lambda row: compare_status(row["çŠ¶æ€åˆ¤æ–­"], row["ä¸Šå‘¨çŠ¶æ€"]), axis=1
        )

        # 3.10 FBA+AWD+åœ¨é€”æ»é”€æ•°é‡ï¼ˆè°ƒç”¨åŠ¨æ€æ»é”€å‡½æ•°ï¼‰
        df["FBA+AWD+åœ¨é€”æ»é”€æ•°é‡"] = df.apply(
            lambda row: calculate_overstock(row, "FBA+AWD+åœ¨é€”åº“å­˜"), axis=1
        ).round().astype(int)

        # 3.11 æ€»æ»é”€åº“å­˜ï¼ˆè°ƒç”¨åŠ¨æ€æ»é”€å‡½æ•°ï¼‰
        df["æ€»æ»é”€åº“å­˜"] = df.apply(
            lambda row: calculate_overstock(row, "å…¨éƒ¨æ€»åº“å­˜"), axis=1
        ).round().astype(int)

        # 3.12 æœ¬åœ°æ»é”€æ•°é‡ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        df["æœ¬åœ°æ»é”€æ•°é‡"] = (df["æ€»æ»é”€åº“å­˜"] - df["FBA+AWD+åœ¨é€”æ»é”€æ•°é‡"]).round().astype(int)
        df["æœ¬åœ°æ»é”€æ•°é‡"] = np.maximum(df["æœ¬åœ°æ»é”€æ•°é‡"], 0)

        # 3.13 é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°ï¼ˆåŸºäºåŠ¨æ€è€—å°½æ—¥æœŸï¼‰
        df["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°"] = (
            (df["é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"] - df["è®°å½•æ—¶é—´"]).dt.total_seconds() / (24 * 3600)
        ).round().astype(int)

        # 3.14 æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡ï¼ˆé€»è¾‘ä¸å˜ï¼Œä¾èµ–åŠ¨æ€æ•°æ®ï¼‰
        days_available = (TARGET_DATE - df["è®°å½•æ—¶é—´"]).dt.days
        days_available = np.maximum(days_available, 1)
        df["æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡"] = np.where(
            df["çŠ¶æ€åˆ¤æ–­"] == "å¥åº·",
            df["æ—¥å‡"],  # å¥åº·çŠ¶æ€ç”¨è¿è¥ç¼–è¾‘çš„æ—¥å‡
            df["å…¨éƒ¨æ€»åº“å­˜"] / days_available
        ).round(2)

        # æœ€ç»ˆæ’åºï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        df = df.sort_values("è®°å½•æ—¶é—´", ascending=False).reset_index(drop=True)
        return df

    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")
        return None




def get_week_data(df, target_date):
    """è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
    target_date = pd.to_datetime(target_date).normalize()
    week_data = df[df["è®°å½•æ—¶é—´"] == target_date].copy()
    return week_data if not week_data.empty else None


def get_previous_week_data(df, current_date):
    """è·å–ä¸Šä¸€å‘¨æ•°æ®ï¼ˆç”¨äºç¯æ¯”è®¡ç®—ï¼‰"""
    current_date = pd.to_datetime(current_date).normalize()
    all_dates = sorted(df["è®°å½•æ—¶é—´"].unique())

    if current_date not in all_dates:
        return None
    current_idx = all_dates.index(current_date)

    if current_idx > 0:
        prev_date = all_dates[current_idx - 1]
        return get_week_data(df, prev_date)
    return None


def calculate_status_metrics(data):
    """è®¡ç®—çŠ¶æ€åˆ†å¸ƒæŒ‡æ ‡"""
    if data is None or data.empty:
        return {"æ€»MSKUæ•°": 0, "å¥åº·": 0, "ä½æ»é”€é£é™©": 0, "ä¸­æ»é”€é£é™©": 0, "é«˜æ»é”€é£é™©": 0}

    total = len(data)
    status_counts = data["çŠ¶æ€åˆ¤æ–­"].value_counts().to_dict()

    metrics = {"æ€»MSKUæ•°": total}
    for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
        metrics[status] = status_counts.get(status, 0)

    return metrics


def compare_with_previous(current_metrics, prev_metrics):
    """è®¡ç®—ç¯æ¯”å˜åŒ–"""
    comparison = {}
    for key in current_metrics:
        curr_val = current_metrics[key]
        prev_val = prev_metrics.get(key, 0) if prev_metrics else 0

        diff = curr_val - prev_val
        pct = (diff / prev_val) * 100 if prev_val != 0 else 0

        # ç¡®å®šé¢œè‰²
        if key == "æ€»MSKUæ•°":
            color = "#000000"
        elif key in ["å¥åº·"]:
            color = "#2E8B57" if diff >= 0 else "#DC143C"
        else:
            color = "#2E8B57" if diff <= 0 else "#DC143C"

        comparison[key] = {
            "å½“å‰å€¼": curr_val,
            "å˜åŒ–å€¼": diff,
            "å˜åŒ–ç‡(%)": round(pct, 1),
            "é¢œè‰²": color
        }
    return comparison


# ------------------------------
# 2. å¯è§†åŒ–ç»„ä»¶å‡½æ•°
# ------------------------------
def render_metric_card(title, current, diff=None, pct=None, color="#000000"):
    """æ¸²æŸ“å¸¦ç¯æ¯”çš„æŒ‡æ ‡å¡ç‰‡"""
    if diff is None:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-title">{title}</div>
            <div class="metric-value" style="color:{color}">{current}</div>
        </div>
        """, unsafe_allow_html=True)
    else:
        diff_symbol = "+" if diff > 0 else ""
        pct_symbol = "+" if pct > 0 else ""
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-title">{title}</div>
            <div class="metric-value" style="color:{color}">{current}</div>
            <div class="metric-change" style="color:{color}">
                {diff_symbol}{diff} ({pct_symbol}{pct}%)
            </div>
        </div>
        """, unsafe_allow_html=True)


# é¦–å…ˆï¼Œæ·»åŠ ä¸€ä¸ªé€šç”¨çš„å¤šçº§ç´¢å¼•è¡¨æ ¼æ¸²æŸ“å‡½æ•°
def render_multi_index_table(data, index_columns, value_columns, page=1, page_size=30, table_id=""):
    """
    æ¸²æŸ“æ”¯æŒäº¤äº’å¼å¤šçº§ç´¢å¼•çš„è¡¨æ ¼

    å‚æ•°:
    - data: è¦æ˜¾ç¤ºçš„æ•°æ®
    - index_columns: ä½œä¸ºç´¢å¼•çš„åˆ—ååˆ—è¡¨ï¼ˆå¤šçº§ç´¢å¼•ï¼‰
    - value_columns: ä½œä¸ºå€¼çš„åˆ—ååˆ—è¡¨
    - page: å½“å‰é¡µç 
    - page_size: æ¯é¡µæ˜¾ç¤ºçš„è®°å½•æ•°
    - table_id: è¡¨æ ¼å”¯ä¸€æ ‡è¯†ï¼Œç”¨äºç¡®ä¿Streamlitç»„ä»¶keyçš„å”¯ä¸€æ€§
    """
    if data.empty:
        st.info("æ²¡æœ‰æ•°æ®å¯æ˜¾ç¤º")
        return 0

    total_rows = len(data)
    total_pages = max(1, (total_rows + page_size - 1) // page_size)

    # åˆ›å»ºå¤šçº§ç´¢å¼•
    multi_index_data = data.set_index(index_columns)

    # åˆ†é¡µå¤„ç†
    start_idx = (page - 1) * page_size
    end_idx = start_idx + page_size
    paginated_data = multi_index_data.iloc[start_idx:end_idx]

    # è½¬æ¢ä¸ºHTMLæ˜¾ç¤ºï¼Œä¿ç•™å¤šçº§ç´¢å¼•ç»“æ„
    html = paginated_data.to_html(
        classes=["dataframe", "table", "table-striped", "table-hover"],
        escape=False,
        na_rep="",
        border=0
    )

    # æ·»åŠ è‡ªå®šä¹‰CSSç¾åŒ–å¤šçº§ç´¢å¼•è¡¨æ ¼
    st.markdown("""
    <style>
    .dataframe th {
        background-color: #f8f9fa;
        text-align: left;
        padding: 8px 12px;
        border-bottom: 2px solid #ddd;
    }
    .dataframe td {
        padding: 8px 12px;
        border-bottom: 1px solid #ddd;
    }
    .dataframe tr:hover {
        background-color: #f1f1f1;
    }
    .dataframe .level0 {
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

    st.markdown(html, unsafe_allow_html=True)

    # åˆ†é¡µæ§åˆ¶
    col1, col2, col3 = st.columns([1, 2, 1])
    with col1:
        if page > 1:
            if st.button("ä¸Šä¸€é¡µ", key=f"prev_page_{table_id}"):
                st.session_state[f"current_page_{table_id}"] = page - 1
                st.rerun()
    with col2:
        st.write(f"ç¬¬ {page} é¡µï¼Œå…± {total_pages} é¡µï¼Œå…± {total_rows} æ¡è®°å½•")
    with col3:
        if page < total_pages:
            if st.button("ä¸‹ä¸€é¡µ", key=f"next_page_{table_id}"):
                st.session_state[f"current_page_{table_id}"] = page + 1
                st.rerun()

    return total_rows


def render_status_distribution_chart(metrics, title):
    """æ¸²æŸ“çŠ¶æ€åˆ†å¸ƒæŸ±çŠ¶å›¾"""
    status_data = pd.DataFrame({
        "çŠ¶æ€": ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"],
        "MSKUæ•°": [metrics[status] for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]]
    })

    fig = px.bar(
        status_data,
        x="çŠ¶æ€",
        y="MSKUæ•°",
        color="çŠ¶æ€",
        color_discrete_map=STATUS_COLORS,
        title=title,
        text="MSKUæ•°",
        height=400,
        # æ·»åŠ è‡ªå®šä¹‰æ•°æ®ï¼Œç”¨äºç‚¹å‡»æ—¶è¯†åˆ«ç­›é€‰æ¡ä»¶
        custom_data = ["çŠ¶æ€"]  # ä¼ é€’â€œçŠ¶æ€â€å­—æ®µä½œä¸ºç­›é€‰æ ‡è¯†
    )

    fig.update_traces(
        textposition="outside",
        textfont=dict(size=12, weight="bold"),
        marker=dict(line=dict(color="#ffffff", width=1))
    )
    fig.update_layout(
        xaxis_title="é£é™©çŠ¶æ€",
        yaxis_title="MSKUæ•°é‡",
        showlegend=False,
        plot_bgcolor="#f8f9fa",
        margin=dict(t=50, b=20, l=20, r=20)
    )
    return fig


def render_days_distribution_chart(data, title):
    """æ¸²æŸ“åº“å­˜å¯ç”¨å¤©æ•°åˆ†å¸ƒå›¾è¡¨ï¼ˆä½¿ç”¨é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°ï¼‰"""
    if data is None or data.empty:
        fig = go.Figure()
        fig.add_annotation(text="æ— æ•°æ®å¯å±•ç¤º", x=0.5, y=0.5, showarrow=False, font=dict(size=16))
        fig.update_layout(title=title, plot_bgcolor="#f8f9fa", height=400)
        return fig

    # ä½¿ç”¨é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°ä½œä¸ºæ¨ªåæ ‡
    valid_days = data["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°"].clip(lower=0)
    today = data["è®°å½•æ—¶é—´"].iloc[0]
    days_to_target = (TARGET_DATE - today).days

    # çŠ¶æ€é˜ˆå€¼
    thresholds = {
        "é«˜æ»é”€é£é™©": days_to_target,
        "ä¸­æ»é”€é£é™©": days_to_target - 14,
        "ä½æ»é”€é£é™©": days_to_target - 30
    }

    fig = px.histogram(
        valid_days,
        nbins=30,
        title=title,
        labels={"value": "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "count": "MSKUæ•°é‡"},
        color_discrete_sequence=["#87CEEB"],
        height=400
    )

    # æ·»åŠ é˜ˆå€¼çº¿ï¼ˆè™šçº¿ï¼‰
    for status, threshold in thresholds.items():
        if threshold >= 0:  # åªæ˜¾ç¤ºåˆç†çš„é˜ˆå€¼çº¿
            fig.add_vline(
                x=threshold,
                line_dash="dash",
                line_color=STATUS_COLORS[status],
                annotation_text=f"{status}é˜ˆå€¼",
                annotation_position="top right",
                annotation_font=dict(color=STATUS_COLORS[status])
            )

    fig.update_layout(
        plot_bgcolor="#f8f9fa",
        margin=dict(t=50, b=20, l=20, r=20),
        xaxis_title="é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°",
        yaxis_title="MSKUæ•°é‡"
    )
    return fig


def render_store_status_table(current_data, prev_data):
    """æ¸²æŸ“åº—é“ºçŠ¶æ€åˆ†å¸ƒè¡¨ï¼ˆå¸¦ç¯æ¯”ï¼‰"""
    if current_data is None or current_data.empty:
        st.markdown("<p>æ— åº—é“ºæ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return

    # ç”Ÿæˆå½“å‰åº—é“ºçŠ¶æ€åˆ†å¸ƒ
    current_pivot = pd.pivot_table(
        current_data,
        index="åº—é“º",
        columns="çŠ¶æ€åˆ¤æ–­",
        values="MSKU",
        aggfunc="count",
        fill_value=0
    ).reindex(columns=["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"], fill_value=0)

    # ç”Ÿæˆä¸Šå‘¨åº—é“ºçŠ¶æ€åˆ†å¸ƒ
    prev_pivot = pd.pivot_table(
        prev_data,
        index="åº—é“º",
        columns="çŠ¶æ€åˆ¤æ–­",
        values="MSKU",
        aggfunc="count",
        fill_value=0
    ).reindex(columns=["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"],
              fill_value=0) if prev_data is not None else None

    # åˆå¹¶å¹¶è®¡ç®—ç¯æ¯”
    html = "<table style='width:100%; border-collapse:collapse;'>"
    html += "<tr><th style='border:1px solid #ddd; padding:8px;'>åº—é“º</th>"
    for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
        html += f"<th style='border:1px solid #ddd; padding:8px; background-color:{STATUS_COLORS[status]}20;'>{status}</th>"
    html += "</tr>"

    for store in current_pivot.index:
        html += f"<tr><td style='border:1px solid #ddd; padding:8px; font-weight:bold;'>{store}</td>"
        for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
            curr = current_pivot.loc[store, status]
            prev = prev_pivot.loc[store, status] if (prev_pivot is not None and store in prev_pivot.index) else 0
            diff = curr - prev

            # ç¡®å®šé¢œè‰²
            if status == "å¥åº·":
                color = "#2E8B57" if diff >= 0 else "#DC143C"
            else:
                color = "#2E8B57" if diff <= 0 else "#DC143C"

            diff_symbol = "+" if diff > 0 else ""
            html += f"<td style='border:1px solid #ddd; padding:8px;'>{curr}<br><span style='color:{color}; font-size:12px;'>{diff_symbol}{diff}</span></td>"
        html += "</tr>"
    html += "</table>"

    st.markdown(html, unsafe_allow_html=True)


def render_product_detail_table(data, prev_data=None, page=1, page_size=30, table_id=""):
    """æ¸²æŸ“äº§å“é£é™©è¯¦æƒ…è¡¨ï¼ˆå¸¦ç¯æ¯”å’Œåˆ†é¡µåŠŸèƒ½ï¼‰"""
    if data is None or data.empty:
        st.markdown("<p style='color:#666'>æ— åŒ¹é…äº§å“æ•°æ®</p>", unsafe_allow_html=True)
        return 0
    # 1. æ·»åŠ è‡ªå®šä¹‰æ’åºé€»è¾‘
    # å®šä¹‰é£é™©çŠ¶æ€çš„æ’åºä¼˜å…ˆçº§
    status_order = {
        "é«˜æ»é”€é£é™©": 0,
        "ä¸­æ»é”€é£é™©": 1,
        "ä½æ»é”€é£é™©": 2,
        "å¥åº·": 3
    }
    # æ·»åŠ æ’åºè¾…åŠ©åˆ—
    data = data.copy()
    data["_sort_key"] = data["çŠ¶æ€åˆ¤æ–­"].map(status_order)
    # å…ˆæŒ‰é£é™©çŠ¶æ€ä¼˜å…ˆçº§å‡åºï¼ˆé«˜é£é™©åœ¨å‰ï¼‰ï¼Œå†æŒ‰æ€»æ»é”€åº“å­˜é™åº
    data = data.sort_values(by=["_sort_key", "æ€»æ»é”€åº“å­˜"], ascending=[True, False])
    # åˆ é™¤ä¸´æ—¶æ’åºåˆ—
    data = data.drop(columns=["_sort_key"])
    # å®šä¹‰è¦æ˜¾ç¤ºçš„åˆ—ï¼ˆæ–°å¢ï¼š4ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼‰
    display_cols = [
        "MSKU", "å“å", "åº—é“º",
        # åŸºç¡€æ—¥å‡åˆ—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
        # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’å…¥ï¼‰
        "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
        "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
        "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
        "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
        # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
        "FBA+AWD+åœ¨é€”åº“å­˜", "æœ¬åœ°å¯ç”¨", "å…¨éƒ¨æ€»åº“å­˜",
        "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ",
        "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡",
        "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
        "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°",
        "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
    ]

    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨ï¼ˆè‡ªåŠ¨è¿‡æ»¤æ•°æ®ä¸­æ²¡æœ‰çš„åˆ—ï¼‰
    available_cols = [col for col in display_cols if col in data.columns]
    table_data = data[available_cols].copy()
    total_rows = len(table_data)

    # è®¡ç®—åˆ†é¡µ
    total_pages = ceil(total_rows / page_size)
    start_idx = (page - 1) * page_size
    end_idx = min(start_idx + page_size, total_rows)
    paginated_data = table_data.iloc[start_idx:end_idx].copy()

    # æ ¼å¼åŒ–æ—¥æœŸï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    date_cols = ["é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"]
    for col in date_cols:
        if col in paginated_data.columns:
            paginated_data[col] = pd.to_datetime(paginated_data[col]).dt.strftime("%Y-%m-%d")

    # æ·»åŠ çŠ¶æ€é¢œè‰²ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    if "çŠ¶æ€åˆ¤æ–­" in paginated_data.columns:
        paginated_data["çŠ¶æ€åˆ¤æ–­"] = paginated_data["çŠ¶æ€åˆ¤æ–­"].apply(
            lambda x: f"<span style='color:{STATUS_COLORS[x]}; font-weight:bold;'>{x}</span>"
        )

    # æ·»åŠ ç¯æ¯”ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šæ–°å¢è°ƒæ•´åæ—¥å‡çš„ç¯æ¯”å¯¹æ¯”ï¼‰
    if prev_data is not None and not prev_data.empty:
        # æ–°å¢ï¼šå°†è°ƒæ•´åæ—¥å‡åˆ—åŠ å…¥prev_mapï¼ˆç”¨äºç¯æ¯”è®¡ç®—ï¼‰
        prev_map = prev_data.set_index("MSKU")[
            ["æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
             "FBA+AWD+åœ¨é€”åº“å­˜","æœ¬åœ°å¯ç”¨",
             "å…¨éƒ¨æ€»åº“å­˜", "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
             "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°",
             # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„è°ƒæ•´åæ—¥å‡ï¼ˆç³»æ•°å›ºå®šï¼Œæ— éœ€ç¯æ¯”ï¼‰
             "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
             "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡"]
        ].to_dict("index")

        def add_compare(row, col):
            msku = row["MSKU"]
            curr_val = row[col]
            prev_val = prev_map.get(msku, {}).get(col, 0)

            if prev_val == 0:
                return f"{curr_val:.2f}<br><span style='color:#666'>æ— æ•°æ®</span>"

            diff = curr_val - prev_val
            pct = (diff / prev_val) * 100
            # ç¡®å®šé¢œè‰²ï¼šæ—¥å‡ä¸Šå‡å¥½ï¼Œæ»é”€æ•°é‡ä¸‹é™å¥½
            if col in ["æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                       # æ–°å¢ï¼šè°ƒæ•´åæ—¥å‡ä¹Ÿå±äº"æ—¥å‡ç±»"ï¼Œä¸Šå‡ä¸ºå¥½
                       "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
                       "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡"]:
                color = "#2E8B57" if diff >= 0 else "#DC143C"
            else:  # åº“å­˜å’Œæ»é”€æ•°é‡ç›¸å…³åˆ—ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
                color = "#2E8B57" if diff <= 0 else "#DC143C"

            diff_symbol = "+" if diff > 0 else ""
            pct_symbol = "+" if pct > 0 else ""
            return f"{curr_val:.2f}<br><span style='color:{color}'>{diff_symbol}{diff:.2f} ({pct_symbol}{pct:.1f}%)</span>"

        # éœ€è¦æ¯”è¾ƒçš„æ•°å€¼åˆ—ï¼ˆæ–°å¢ï¼šè°ƒæ•´åæ—¥å‡åˆ—ï¼‰
        numeric_cols = [
            "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
            # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„è°ƒæ•´åæ—¥å‡ï¼ˆç³»æ•°å›ºå®šï¼Œæ— éœ€ç¯æ¯”ï¼‰
            "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
            "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
            # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
            "FBA+AWD+åœ¨é€”åº“å­˜","æœ¬åœ°å¯ç”¨",
            "å…¨éƒ¨æ€»åº“å­˜", "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
            "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°"
        ]
        for col in numeric_cols:
            if col in paginated_data.columns:
                paginated_data[col] = paginated_data.apply(lambda x: add_compare(x, col), axis=1)

    # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    st.markdown(paginated_data.to_html(escape=False, index=False), unsafe_allow_html=True)

    # æ˜¾ç¤ºåˆ†é¡µæŒ‰é’®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    col1, col2, col3 = st.columns([1, 2, 1])
    with col1:
        if page > 1:
            # æ·»åŠ table_idå‚æ•°ä½¿keyå”¯ä¸€
            if st.button("ä¸Šä¸€é¡µ", key=f"prev_page_{table_id}"):
                st.session_state.current_page = page - 1
                st.rerun()
    with col2:
        st.write(f"ç¬¬ {page} é¡µï¼Œå…± {total_pages} é¡µï¼Œå…± {total_rows} æ¡è®°å½•")
    with col3:
        if page < total_pages:
            # æ·»åŠ table_idå‚æ•°ä½¿keyå”¯ä¸€
            if st.button("ä¸‹ä¸€é¡µ", key=f"next_page_{table_id}"):
                st.session_state.current_page = page + 1
                st.rerun()

    return total_rows


def render_four_week_comparison_table(df, date_list):
    """æ¸²æŸ“è¿‘å››å‘¨æ¦‚è§ˆè¡¨ï¼ˆå¸¦ç¯æ¯”å˜åŒ–å€¼ï¼‰"""
    if len(date_list) < 1:
        st.markdown("<p>æ— æ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return

    # ç¡®ä¿æˆ‘ä»¬æœ‰æœ€å¤šå››å‘¨çš„æ•°æ®ï¼ˆæ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šå°†3æ”¹ä¸º4ï¼‰
    display_dates = date_list[-4:] if len(date_list) >= 4 else date_list
    date_labels = [d.strftime("%Y-%m-%d") for d in display_dates]

    # åˆ›å»ºæ¯”è¾ƒè¡¨æ•°æ®
    comparison_data = []

    for i, date in enumerate(display_dates):
        data = get_week_data(df, date)
        metrics = calculate_status_metrics(data)

        # è®¡ç®—ç¯æ¯”
        if i > 0:
            prev_data = get_week_data(df, display_dates[i - 1])
            prev_metrics = calculate_status_metrics(prev_data)
            comparisons = compare_with_previous(metrics, prev_metrics)
        else:
            comparisons = None

        # æ·»åŠ è¡Œæ•°æ®
        row = {
            "æ—¥æœŸ": date_labels[i],
            "æ€»MSKUæ•°": metrics["æ€»MSKUæ•°"],
            "å¥åº·": metrics["å¥åº·"],
            "ä½æ»é”€é£é™©": metrics["ä½æ»é”€é£é™©"],
            "ä¸­æ»é”€é£é™©": metrics["ä¸­æ»é”€é£é™©"],
            "é«˜æ»é”€é£é™©": metrics["é«˜æ»é”€é£é™©"]
        }

        # æ·»åŠ ç¯æ¯”å˜åŒ–
        if comparisons:
            row["æ€»MSKUæ•°å˜åŒ–"] = comparisons["æ€»MSKUæ•°"]["å˜åŒ–å€¼"]
            row["å¥åº·å˜åŒ–"] = comparisons["å¥åº·"]["å˜åŒ–å€¼"]
            row["ä½æ»é”€é£é™©å˜åŒ–"] = comparisons["ä½æ»é”€é£é™©"]["å˜åŒ–å€¼"]
            row["ä¸­æ»é”€é£é™©å˜åŒ–"] = comparisons["ä¸­æ»é”€é£é™©"]["å˜åŒ–å€¼"]
            row["é«˜æ»é”€é£é™©å˜åŒ–"] = comparisons["é«˜æ»é”€é£é™©"]["å˜åŒ–å€¼"]

            row["æ€»MSKUæ•°å˜åŒ–ç‡"] = comparisons["æ€»MSKUæ•°"]["å˜åŒ–ç‡(%)"]
            row["å¥åº·å˜åŒ–ç‡"] = comparisons["å¥åº·"]["å˜åŒ–ç‡(%)"]
            row["ä½æ»é”€é£é™©å˜åŒ–ç‡"] = comparisons["ä½æ»é”€é£é™©"]["å˜åŒ–ç‡(%)"]
            row["ä¸­æ»é”€é£é™©å˜åŒ–ç‡"] = comparisons["ä¸­æ»é”€é£é™©"]["å˜åŒ–ç‡(%)"]
            row["é«˜æ»é”€é£é™©å˜åŒ–ç‡"] = comparisons["é«˜æ»é”€é£é™©"]["å˜åŒ–ç‡(%)"]

        comparison_data.append(row)

    # åˆ›å»ºHTMLè¡¨æ ¼
    html = "<table style='width:100%; border-collapse:collapse;'>"
    html += "<tr><th style='border:1px solid #ddd; padding:8px;'>æ—¥æœŸ</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>æ€»MSKUæ•°</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>å¥åº·</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>ä½æ»é”€é£é™©</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>ä¸­æ»é”€é£é™©</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>é«˜æ»é”€é£é™©</th></tr>"

    for row in comparison_data:
        html += f"<tr><td style='border:1px solid #ddd; padding:8px; font-weight:bold;'>{row['æ—¥æœŸ']}</td>"

        # æ€»MSKUæ•°
        if "æ€»MSKUæ•°å˜åŒ–" in row:
            diff = row["æ€»MSKUæ•°å˜åŒ–"]
            color = "#2E8B57" if diff >= 0 else "#DC143C"
            symbol = "+" if diff > 0 else ""
            html += f"<td style='border:1px solid #ddd; padding:8px;'>{row['æ€»MSKUæ•°']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
        else:
            html += f"<td style='border:1px solid #ddd; padding:8px;'>{row['æ€»MSKUæ•°']}</td>"

        # å¥åº·
        if "å¥åº·å˜åŒ–" in row:
            diff = row["å¥åº·å˜åŒ–"]
            color = "#2E8B57" if diff >= 0 else "#DC143C"
            symbol = "+" if diff > 0 else ""
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['å¥åº·']};'>{row['å¥åº·']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
        else:
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['å¥åº·']};'>{row['å¥åº·']}</td>"

        # ä½æ»é”€é£é™©
        if "ä½æ»é”€é£é™©å˜åŒ–" in row:
            diff = row["ä½æ»é”€é£é™©å˜åŒ–"]
            color = "#2E8B57" if diff <= 0 else "#DC143C"
            symbol = "+" if diff > 0 else ""
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['ä½æ»é”€é£é™©']};'>{row['ä½æ»é”€é£é™©']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
        else:
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['ä½æ»é”€é£é™©']};'>{row['ä½æ»é”€é£é™©']}</td>"

        # ä¸­æ»é”€é£é™©
        if "ä¸­æ»é”€é£é™©å˜åŒ–" in row:
            diff = row["ä¸­æ»é”€é£é™©å˜åŒ–"]
            color = "#2E8B57" if diff <= 0 else "#DC143C"
            symbol = "+" if diff > 0 else ""
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['ä¸­æ»é”€é£é™©']};'>{row['ä¸­æ»é”€é£é™©']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
        else:
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['ä¸­æ»é”€é£é™©']};'>{row['ä¸­æ»é”€é£é™©']}</td>"

        # é«˜æ»é”€é£é™©
        if "é«˜æ»é”€é£é™©å˜åŒ–" in row:
            diff = row["é«˜æ»é”€é£é™©å˜åŒ–"]
            color = "#2E8B57" if diff <= 0 else "#DC143C"
            symbol = "+" if diff > 0 else ""
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['é«˜æ»é”€é£é™©']};'>{row['é«˜æ»é”€é£é™©']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
        else:
            html += f"<td style='border:1px solid #ddd; padding:8px; color:{STATUS_COLORS['é«˜æ»é”€é£é™©']};'>{row['é«˜æ»é”€é£é™©']}</td>"

        html += "</tr>"

    html += "</table>"
    st.markdown(html, unsafe_allow_html=True)


def render_four_week_status_chart(df, date_list):
    """å››å‘¨çŠ¶æ€å˜åŒ–è¶‹åŠ¿ï¼ˆæŸ±çŠ¶å›¾ç‰ˆæœ¬ï¼‰"""
    if len(date_list) < 1:
        fig = go.Figure()
        fig.add_annotation(text="æ— æ•°æ®å¯å±•ç¤º", x=0.5, y=0.5, showarrow=False, font=dict(size=16))
        fig.update_layout(title="å››å‘¨çŠ¶æ€å˜åŒ–è¶‹åŠ¿", plot_bgcolor="#f8f9fa", height=400)
        return fig

    # è·å–æœ€å¤šå››å‘¨æ•°æ®ï¼ˆæ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šå°†3æ”¹ä¸º4ï¼‰
    display_dates = date_list[-4:] if len(date_list) >= 4 else date_list
    date_labels = [d.strftime("%Y-%m-%d") for d in display_dates]

    # å‡†å¤‡æ•°æ®
    trend_data = []
    for date, label in zip(display_dates, date_labels):
        data = get_week_data(df, date)
        metrics = calculate_status_metrics(data)

        for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
            trend_data.append({
                "æ—¥æœŸ": label,
                "çŠ¶æ€": status,
                "MSKUæ•°": metrics[status]
            })

    trend_df = pd.DataFrame(trend_data)

    # åˆ›å»ºæŸ±çŠ¶å›¾
    fig = px.bar(
        trend_df,
        x="çŠ¶æ€",
        y="MSKUæ•°",
        color="æ—¥æœŸ",
        barmode="group",
        title="å››å‘¨çŠ¶æ€å˜åŒ–è¶‹åŠ¿",  # ä¿®æ”¹æ ‡é¢˜
        text="MSKUæ•°",
        height=400
    )

    fig.update_traces(
        textposition="outside",
        textfont=dict(size=12)
    )

    fig.update_layout(
        xaxis_title="é£é™©çŠ¶æ€",
        yaxis_title="MSKUæ•°é‡",
        plot_bgcolor="#f8f9fa",
        margin=dict(t=50, b=20, l=20, r=20)
    )

    return fig



def render_store_trend_charts(df, date_list):
    """æ¸²æŸ“æ¯ä¸ªåº—é“ºçš„çŠ¶æ€è¶‹åŠ¿æŠ˜çº¿å›¾ï¼ˆåˆ†ä¸¤åˆ—æ˜¾ç¤ºï¼‰"""
    if len(date_list) < 1:
        st.markdown("<p>æ— æ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return

    # è·å–æ‰€æœ‰åº—é“º
    all_data = pd.concat([get_week_data(df, date) for date in date_list])
    if all_data is None or all_data.empty:
        st.markdown("<p>æ— åº—é“ºæ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return

    stores = sorted(all_data["åº—é“º"].unique())
    date_labels = [d.strftime("%Y-%m-%d") for d in date_list]

    # åˆ†ä¸¤åˆ—æ˜¾ç¤ºå›¾è¡¨
    cols = st.columns(2)
    for i, store in enumerate(stores):
        # å‡†å¤‡åº—é“ºæ•°æ®
        store_data = []
        for date, label in zip(date_list, date_labels):
            data = get_week_data(df, date)
            if data is not None and not data.empty:
                store_status_data = data[data["åº—é“º"] == store]
                metrics = calculate_status_metrics(store_status_data)

                for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
                    store_data.append({
                        "æ—¥æœŸ": label,
                        "çŠ¶æ€": status,
                        "MSKUæ•°": metrics[status]
                    })

        if not store_data:
            continue

        store_df = pd.DataFrame(store_data)

        # åˆ›å»ºæŠ˜çº¿å›¾
        fig = go.Figure()
        for status in ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
            status_data = store_df[store_df["çŠ¶æ€"] == status]
            fig.add_trace(go.Scatter(
                x=status_data["æ—¥æœŸ"],
                y=status_data["MSKUæ•°"],
                mode="lines+markers",
                name=status,
                line=dict(color=STATUS_COLORS[status], width=2),
                marker=dict(size=8)
            ))

        fig.update_layout(
            title=f"{store} çŠ¶æ€å˜åŒ–è¶‹åŠ¿",
            xaxis_title="æ—¥æœŸ",
            yaxis_title="MSKUæ•°é‡",
            plot_bgcolor="#f8f9fa",
            height=300,
            margin=dict(t=50, b=20, l=20, r=20)
        )

        # åœ¨å¯¹åº”åˆ—æ˜¾ç¤ºå›¾è¡¨
        with cols[i % 2]:
            st.plotly_chart(fig, use_container_width=True)


def render_store_weekly_changes(df, date_list):
    """æ¸²æŸ“åº—é“ºæ¯å‘¨å˜åŒ–æƒ…å†µè¡¨"""
    if len(date_list) < 1:
        st.markdown("<p>æ— æ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return

    # è·å–æ‰€æœ‰åº—é“º
    all_data = pd.concat([get_week_data(df, date) for date in date_list])
    if all_data is None or all_data.empty:
        st.markdown("<p>æ— åº—é“ºæ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return

    stores = sorted(all_data["åº—é“º"].unique())
    date_labels = [d.strftime("%Y-%m-%d") for d in date_list]

    # åˆ›å»ºHTMLè¡¨æ ¼
    html = "<table style='width:100%; border-collapse:collapse;'>"
    html += "<tr><th style='border:1px solid #ddd; padding:8px;'>åº—é“º</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>æ—¥æœŸ</th>"
    html += "<th style='border:1px solid #ddd; padding:8px;'>æ€»MSKUæ•°</th>"
    html += "<th style='border:1px solid #ddd; padding:8px; background-color:#2E8B5720;'>å¥åº·</th>"
    html += "<th style='border:1px solid #ddd; padding:8px; background-color:#4169E120;'>ä½æ»é”€é£é™©</th>"
    html += "<th style='border:1px solid #ddd; padding:8px; background-color:#FFD70020;'>ä¸­æ»é”€é£é™©</th>"
    html += "<th style='border:1px solid #ddd; padding:8px; background-color:#DC143C20;'>é«˜æ»é”€é£é™©</th></tr>"

    for store in stores:
        for i, (date, label) in enumerate(zip(date_list, date_labels)):
            data = get_week_data(df, date)
            if data is not None and not data.empty:
                store_status_data = data[data["åº—é“º"] == store]
                metrics = calculate_status_metrics(store_status_data)

                # è·å–ä¸Šå‘¨æ•°æ®
                prev_metrics = None
                if i > 0:
                    prev_data = get_week_data(df, date_list[i - 1])
                    if prev_data is not None and not prev_data.empty:
                        prev_store_data = prev_data[prev_data["åº—é“º"] == store]
                        prev_metrics = calculate_status_metrics(prev_store_data)

                # å¼€å§‹è¡Œ
                html += f"<tr><td style='border:1px solid #ddd; padding:8px; font-weight:bold;'>{store}</td>"
                html += f"<td style='border:1px solid #ddd; padding:8px;'>{label}</td>"

                # æ€»MSKUæ•°
                if prev_metrics:
                    diff = metrics["æ€»MSKUæ•°"] - prev_metrics["æ€»MSKUæ•°"]
                    color = "#2E8B57" if diff >= 0 else "#DC143C"
                    symbol = "+" if diff > 0 else ""
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['æ€»MSKUæ•°']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
                else:
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['æ€»MSKUæ•°']}</td>"

                # å¥åº·
                if prev_metrics:
                    diff = metrics["å¥åº·"] - prev_metrics["å¥åº·"]
                    color = "#2E8B57" if diff >= 0 else "#DC143C"
                    symbol = "+" if diff > 0 else ""
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['å¥åº·']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
                else:
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['å¥åº·']}</td>"

                # ä½æ»é”€é£é™©
                if prev_metrics:
                    diff = metrics["ä½æ»é”€é£é™©"] - prev_metrics["ä½æ»é”€é£é™©"]
                    color = "#2E8B57" if diff <= 0 else "#DC143C"
                    symbol = "+" if diff > 0 else ""
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['ä½æ»é”€é£é™©']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
                else:
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['ä½æ»é”€é£é™©']}</td>"

                # ä¸­æ»é”€é£é™©
                if prev_metrics:
                    diff = metrics["ä¸­æ»é”€é£é™©"] - prev_metrics["ä¸­æ»é”€é£é™©"]
                    color = "#2E8B57" if diff <= 0 else "#DC143C"
                    symbol = "+" if diff > 0 else ""
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['ä¸­æ»é”€é£é™©']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
                else:
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['ä¸­æ»é”€é£é™©']}</td>"

                # é«˜æ»é”€é£é™©
                if prev_metrics:
                    diff = metrics["é«˜æ»é”€é£é™©"] - prev_metrics["é«˜æ»é”€é£é™©"]
                    color = "#2E8B57" if diff <= 0 else "#DC143C"
                    symbol = "+" if diff > 0 else ""
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['é«˜æ»é”€é£é™©']}<br><span style='color:{color}; font-size:12px;'>{symbol}{diff}</span></td>"
                else:
                    html += f"<td style='border:1px solid #ddd; padding:8px;'>{metrics['é«˜æ»é”€é£é™©']}</td>"

                html += "</tr>"

    html += "</table>"
    st.markdown(html, unsafe_allow_html=True)


def render_status_change_table(data, page=1, page_size=30):
    """æ¸²æŸ“ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–è¡¨ï¼ˆå¸¦å¤šçº§ç´¢å¼•å’Œåˆ†é¡µï¼‰"""
    if data is None or data.empty:
        st.markdown("<p style='color:#666'>æ— æ•°æ®å¯å±•ç¤º</p>", unsafe_allow_html=True)
        return 0

    # æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨display_colsä¸­æ–°å¢8ä¸ªåˆ—ï¼ˆ4ä¸ªç³»æ•°+4ä¸ªè°ƒæ•´åæ—¥å‡ï¼‰
    display_cols = [
        "MSKU", "å“å", "åº—é“º", "è®°å½•æ—¶é—´",
        # åŸºç¡€æ—¥å‡åˆ—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
        "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
        # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’å…¥ï¼‰
        "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
        "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
        "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
        "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
        # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
        "FBA+AWD+åœ¨é€”åº“å­˜","æœ¬åœ°å¯ç”¨", "å…¨éƒ¨æ€»åº“å­˜", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ",
        "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡", "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
        "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°", "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
    ]

    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨ï¼ˆè‡ªåŠ¨è¿‡æ»¤æ•°æ®ä¸­æ²¡æœ‰çš„åˆ—ï¼Œæ–°å¢åˆ—ä¼šè¢«è‡ªåŠ¨çº³å…¥ï¼‰
    available_cols = [col for col in display_cols if col in data.columns]
    table_data = data[available_cols].copy()
    total_rows = len(table_data)

    # è®¡ç®—åˆ†é¡µï¼ˆä¿æŒåŸé€»è¾‘ï¼Œæ–°å¢åˆ—ä¸å½±å“åˆ†é¡µï¼‰
    total_pages = ceil(total_rows / page_size)
    start_idx = (page - 1) * page_size
    end_idx = min(start_idx + page_size, total_rows)
    paginated_data = table_data.iloc[start_idx:end_idx].copy()

    # æ ¼å¼åŒ–æ—¥æœŸï¼ˆä¿æŒåŸé€»è¾‘ï¼Œä¸å½±å“æ–°å¢åˆ—ï¼‰
    date_cols = ["è®°å½•æ—¶é—´", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"]
    for col in date_cols:
        if col in paginated_data.columns:
            paginated_data[col] = pd.to_datetime(paginated_data[col]).dt.strftime("%Y-%m-%d")

    # æ·»åŠ çŠ¶æ€é¢œè‰²ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    if "çŠ¶æ€åˆ¤æ–­" in paginated_data.columns:
        paginated_data["çŠ¶æ€åˆ¤æ–­"] = paginated_data["çŠ¶æ€åˆ¤æ–­"].apply(
            lambda x: f"<span style='color:{STATUS_COLORS[x]}; font-weight:bold;'>{x}</span>"
        )

    # æ·»åŠ ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–é¢œè‰²ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    if "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–" in paginated_data.columns:
        def color_status_change(x):
            if x == "æ”¹å–„":
                return f"<span style='color:#2E8B57; font-weight:bold;'>{x}</span>"
            elif x == "æ¶åŒ–":
                return f"<span style='color:#DC143C; font-weight:bold;'>{x}</span>"
            else:  # ç»´æŒä¸å˜
                return f"<span style='color:#000000; font-weight:bold;'>{x}</span>"

        paginated_data["ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"] = paginated_data["ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"].apply(color_status_change)

    # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œæ–°å¢åˆ—ä¼šè‡ªåŠ¨æ¸²æŸ“ï¼‰
    st.markdown(paginated_data.to_html(escape=False, index=False), unsafe_allow_html=True)

    # æ˜¾ç¤ºåˆ†é¡µæŒ‰é’®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    col1, col2, col3 = st.columns([1, 2, 1])
    with col1:
        if page > 1:
            # ä½¿ç”¨ä¸åŒçš„keyå€¼
            if st.button("ä¸Šä¸€é¡µ", key="prev_page_status"):
                st.session_state.current_status_page = page - 1
                st.rerun()
    with col2:
        st.write(f"ç¬¬ {page} é¡µï¼Œå…± {total_pages} é¡µï¼Œå…± {total_rows} æ¡è®°å½•")
    with col3:
        if page < total_pages:
            # ä½¿ç”¨ä¸åŒçš„keyå€¼
            if st.button("ä¸‹ä¸€é¡µ", key="next_page_status"):
                st.session_state.current_status_page = page + 1
                st.rerun()

    return total_rows


# åœ¨ç°æœ‰ä»£ç çš„å¯è§†åŒ–ç»„ä»¶åŒºåŸŸæ·»åŠ ä»¥ä¸‹ä»£ç 




def render_risk_summary_table(summary_df):
    """åœ¨Streamlitä¸­æ¸²æŸ“é£é™©æ±‡æ€»è¡¨æ ¼"""
    st.subheader("åº“å­˜é£é™©çŠ¶æ€æ±‡æ€»è¡¨")

    # è‡ªå®šä¹‰è¡¨æ ¼æ ·å¼
    st.markdown("""
    <style>
    .summary-table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
    }
    .summary-table th, .summary-table td {
        padding: 12px 15px;
        text-align: left;
        border-bottom: 1px solid #ddd;
    }
    .summary-table th {
        background-color: #f8f9fa;
        font-weight: bold;
    }
    .summary-table tr:hover {
        background-color: #f5f5f5;
    }
    .positive-change {
        color: #28a745;  /* ç»¿è‰²ï¼šå¥åº·çŠ¶æ€å¢åŠ /é£é™©çŠ¶æ€å‡å°‘ */
    }
    .negative-change {
        color: #dc3545;  /* çº¢è‰²ï¼šå¥åº·çŠ¶æ€å‡å°‘/é£é™©çŠ¶æ€å¢åŠ  */
    }
    </style>
    """, unsafe_allow_html=True)

    # æ¸²æŸ“è¡¨æ ¼
    html = "<table class='summary-table'>"
    # è¡¨å¤´
    html += "<tr>"
    for col in summary_df.columns:
        html += f"<th>{col}</th>"
    html += "</tr>"

    # è¡¨å†…å®¹
    for _, row in summary_df.iterrows():
        html += "<tr>"
        for col, value in row.items():
            if col == "çŠ¶æ€åˆ¤æ–­":
                # ä¸ºçŠ¶æ€æ·»åŠ é¢œè‰²ï¼ˆå¤ç”¨å…¨å±€STATUS_COLORSï¼Œåˆå¹¶çŠ¶æ€ç”¨é»˜è®¤è‰²ï¼‰
                color = STATUS_COLORS.get(value, "#000000")  # éåŸºç¡€çŠ¶æ€ç”¨é»‘è‰²
                html += f"<td style='color:{color}; font-weight:bold;'>{value}</td>"
            elif "ç¯æ¯”å˜åŒ–" in col:
                # æ ‡è®°æ­£è´Ÿå˜åŒ–ï¼ˆåŒºåˆ†çŠ¶æ€ç±»å‹ï¼‰
                if '(' in str(value):
                    change_val = float(value.split()[0])  # æå–å˜åŒ–å€¼
                    status = row["çŠ¶æ€åˆ¤æ–­"]  # è·å–å½“å‰è¡Œçš„çŠ¶æ€

                    # å¥åº·çŠ¶æ€ï¼šå¢åŠ ä¸ºæ­£ï¼›é£é™©çŠ¶æ€ï¼šå‡å°‘ä¸ºæ­£
                    if status == "å¥åº·":
                        is_positive = change_val >= 0
                    else:
                        is_positive = change_val <= 0

                    if is_positive:
                        html += f"<td class='positive-change'>{value}</td>"
                    else:
                        html += f"<td class='negative-change'>{value}</td>"
                else:
                    html += f"<td>{value}</td>"
            else:
                html += f"<td>{value}</td>"
        html += "</tr>"
    html += "</table>"

    st.markdown(html, unsafe_allow_html=True)


def create_risk_summary_table(current_data, previous_data):
    statuses = [
        "å¥åº·",
        "ä½æ»é”€é£é™©",
        "ä¸­æ»é”€é£é™©",
        "é«˜æ»é”€é£é™©",
        "ä½æ»é”€é£é™©+ä¸­æ»é”€é£é™©+é«˜æ»é”€é£é™©",
        "ä¸­æ»é”€é£é™©+é«˜æ»é”€é£é™©"
    ]
    status_mappings = {
        "å¥åº·": ["å¥åº·"],
        "ä½æ»é”€é£é™©": ["ä½æ»é”€é£é™©"],
        "ä¸­æ»é”€é£é™©": ["ä¸­æ»é”€é£é™©"],
        "é«˜æ»é”€é£é™©": ["é«˜æ»é”€é£é™©"],
        "ä½æ»é”€é£é™©+ä¸­æ»é”€é£é™©+é«˜æ»é”€é£é™©": ["ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"],
        "ä¸­æ»é”€é£é™©+é«˜æ»é”€é£é™©": ["ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]
    }

    # è®¡ç®—å½“å‰å‘¨æœŸçš„æ€»MSKUå’Œæ€»æ»é”€åº“å­˜ï¼ˆç”¨äºè®¡ç®—å æ¯”ï¼‰
    total_current_msku = current_data['MSKU'].nunique() if current_data is not None and not current_data.empty else 0
    total_current_inventory = current_data[
        'æ€»æ»é”€åº“å­˜'].sum() if current_data is not None and not current_data.empty else 0

    summary_data = []
    for status in statuses:
        original_statuses = status_mappings[status]

        # ç­›é€‰å½“å‰å‘¨æœŸæ•°æ®
        current_filtered = current_data[current_data['çŠ¶æ€åˆ¤æ–­'].isin(original_statuses)] if (
                    current_data is not None and not current_data.empty) else pd.DataFrame()
        current_msku = current_filtered['MSKU'].nunique() if not current_filtered.empty else 0
        current_inventory = current_filtered['æ€»æ»é”€åº“å­˜'].sum() if not current_filtered.empty else 0

        # å¤„ç†ä¸Šä¸€å‘¨æœŸæ•°æ®
        if previous_data is not None and not previous_data.empty:
            prev_filtered = previous_data[previous_data['çŠ¶æ€åˆ¤æ–­'].isin(original_statuses)]
            prev_msku = prev_filtered['MSKU'].nunique() if not prev_filtered.empty else 0
            prev_inventory = prev_filtered['æ€»æ»é”€åº“å­˜'].sum() if not prev_filtered.empty else 0
        else:
            prev_msku = 0
            prev_inventory = 0

        # è®¡ç®—ç¯æ¯”
        msku_change = current_msku - prev_msku
        msku_change_pct = (msku_change / prev_msku * 100) if prev_msku != 0 else 0
        inventory_change = current_inventory - prev_inventory
        inventory_change_pct = (inventory_change / prev_inventory * 100) if prev_inventory != 0 else 0

        # æ–°å¢ï¼šè®¡ç®—å æ¯”ï¼ˆå½“å‰çŠ¶æ€å€¼ / æ€»å€¼ï¼‰
        msku_ratio = (current_msku / total_current_msku * 100) if total_current_msku != 0 else 0
        inventory_ratio = (current_inventory / total_current_inventory * 100) if total_current_inventory != 0 else 0

        summary_data.append({
            "çŠ¶æ€åˆ¤æ–­": status,
            "MSKUæ•°": current_msku,
            "MSKUå æ¯”": f"{msku_ratio:.1f}%",  # æ–°å¢ï¼šMSKUå æ¯”ï¼ˆä¿ç•™1ä½å°æ•°ï¼‰
            "MSKUç¯æ¯”å˜åŒ–": f"{msku_change} ({msku_change_pct:.1f}%)",
            "æ€»æ»é”€åº“å­˜æ•°": round(current_inventory, 2),
            "æ€»æ»é”€åº“å­˜å æ¯”": f"{inventory_ratio:.1f}%",  # æ–°å¢ï¼šåº“å­˜å æ¯”ï¼ˆä¿ç•™1ä½å°æ•°ï¼‰
            "åº“å­˜ç¯æ¯”å˜åŒ–": f"{round(inventory_change, 2)} ({inventory_change_pct:.1f}%)"
        })

    return pd.DataFrame(summary_data)

def render_stock_forecast_chart(data, msku):
    """æ¸²æŸ“å•ä¸ªMSKUçš„åº“å­˜é¢„æµ‹å›¾è¡¨ï¼ˆä»è®°å½•æ—¶é—´åˆ°2025å¹´12æœˆ31æ—¥ï¼Œå«åˆ†é˜¶æ®µç³»æ•°ï¼‰"""
    if data is None or data.empty:
        fig = go.Figure()
        fig.add_annotation(text="æ— æ•°æ®å¯å±•ç¤º", x=0.5, y=0.5, showarrow=False, font=dict(size=16))
        fig.update_layout(title=f"{msku} åº“å­˜é¢„æµ‹", plot_bgcolor="#f8f9fa", height=400)
        return fig

    row = data.iloc[0]
    start_date = row["è®°å½•æ—¶é—´"]  # è®°å½•æ—¶é—´
    end_date = END_DATE  # 2025å¹´12æœˆ31æ—¥
    base_avg = row["æ—¥å‡"] if row["æ—¥å‡"] > 0 else 0.1  # åŸºç¡€æ—¥å‡
    total_stock = row["å…¨éƒ¨æ€»åº“å­˜"]
    remaining_stock = total_stock

    # 1. å®šä¹‰æ—¶é—´æ®µç³»æ•°ï¼ˆéœ€ä¸load_and_preprocess_data_from_dfä¿æŒä¸€è‡´ï¼‰
    TIME_PERIODS = [
        {"start": datetime(2025, 10, 15), "end": datetime(2025, 10, 31), "coefficient": 0.95},
        {"start": datetime(2025, 11, 1), "end": datetime(2025, 11, 15), "coefficient": 0.91},
        {"start": datetime(2025, 11, 16), "end": datetime(2025, 11, 30), "coefficient": 0.72},
        {"start": datetime(2025, 12, 1), "end": datetime(2025, 12, 31), "coefficient": 0.43}
    ]

    # 2. åˆ†é˜¶æ®µè®¡ç®—å‰©ä½™åº“å­˜ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
    forecast_dates = []
    forecast_stock = []
    current_date = start_date

    while current_date <= end_date and remaining_stock > 0:
        # ç¡®å®šå½“å‰æ—¥æœŸå¯¹åº”çš„ç³»æ•°
        current_coeff = 1.0  # é»˜è®¤ç³»æ•°1.0
        for period in TIME_PERIODS:
            if period["start"] <= current_date <= period["end"]:
                current_coeff = period["coefficient"]
                break

        # è®¡ç®—å½“å¤©çš„é”€é‡ï¼ˆåŸºç¡€æ—¥å‡Ã—å½“å‰ç³»æ•°ï¼‰
        daily_sales = base_avg * current_coeff
        # æ‰£å‡åº“å­˜ï¼ˆç¡®ä¿ä¸å°äº0ï¼‰
        remaining_stock = max(remaining_stock - daily_sales, 0)

        # è®°å½•æ—¥æœŸå’Œåº“å­˜
        forecast_dates.append(current_date)
        forecast_stock.append(remaining_stock)

        # æ—¥æœŸ+1å¤©
        current_date += timedelta(days=1)

    # 3. ç”ŸæˆæŠ˜çº¿å›¾ï¼ˆä½¿ç”¨åˆ†é˜¶æ®µè®¡ç®—çš„ç»“æœï¼‰
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=forecast_dates,
        y=forecast_stock,
        mode="lines+markers",
        line=dict(color="#4169E1", width=2),
        name="é¢„è®¡åº“å­˜ï¼ˆåˆ†é˜¶æ®µç³»æ•°ï¼‰"
    ))

    # 4. æ·»åŠ ç›®æ ‡æ—¥æœŸçº¿ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.add_vline(
        x=TARGET_DATE.timestamp() * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³
        line_dash="dash",
        line_color="#DC143C",  # çº¢è‰²
        annotation_text="ç›®æ ‡æ¶ˆè€—æ—¥æœŸ",
        annotation_position="top right",
        annotation_font=dict(color="#DC143C")
    )

    # 5. æ·»åŠ æ—¶é—´æ®µç³»æ•°æ ‡æ³¨ï¼ˆå¯é€‰ï¼Œå¢å¼ºå¯è¯»æ€§ï¼‰
    for period in TIME_PERIODS:
        # åœ¨æ—¶é—´æ®µèµ·å§‹ä½ç½®æ·»åŠ ç³»æ•°æ ‡æ³¨
        fig.add_annotation(
            x=period["start"],
            y=max(forecast_stock) * 0.9,  # æ ‡æ³¨ä½ç½®åœ¨åº“å­˜å³°å€¼çš„90%å¤„
            text=f"{period['start'].strftime('%m-%d')}èµ·ç³»æ•°: {period['coefficient']}",
            showarrow=True,
            arrowhead=1,
            arrowcolor=STATUS_COLORS["ä½æ»é”€é£é™©"],
            font=dict(size=10, color=STATUS_COLORS["ä½æ»é”€é£é™©"])
        )

    # 6. å›¾è¡¨å¸ƒå±€ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.update_layout(
        title=f"{msku} åº“å­˜æ¶ˆè€—é¢„æµ‹ï¼ˆå«åˆ†é˜¶æ®µé”€é‡ç³»æ•°ï¼‰",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="å‰©ä½™åº“å­˜",
        plot_bgcolor="#f8f9fa",
        height=400,
        margin=dict(t=50, b=20, l=20, r=20)
    )

    # 7. æ¨ªåæ ‡è®¾ç½®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=30, label="30å¤©", step="day", stepmode="backward"),
                dict(count=1, label="1æœˆ", step="month", stepmode="backward"),
                dict(step="all", label="å…¨éƒ¨")
            ])
        ),
        type="date",
        tickformat="%Yå¹´%mæœˆ%dæ—¥",
        dtick=864000000,  # 10å¤©çš„æ¯«ç§’æ•°
        ticklabelmode="period"
    )

    return fig


def render_product_detail_chart(df, msku):
    """æ¸²æŸ“å•ä¸ªäº§å“çš„å†å²åº“å­˜é¢„æµ‹å¯¹æ¯”å›¾ï¼ˆå«åˆ†é˜¶æ®µç³»æ•°ï¼‰"""
    if df is None or df.empty:
        fig = go.Figure()
        fig.add_annotation(text="æ— æ•°æ®å¯å±•ç¤º", x=0.5, y=0.5, showarrow=False, font=dict(size=16))
        fig.update_layout(title=f"{msku} å†å²åº“å­˜é¢„æµ‹", plot_bgcolor="#f8f9fa", height=400)
        return fig

    # è·å–è¯¥MSKUçš„æ‰€æœ‰è®°å½•
    product_data = df[df["MSKU"] == msku].sort_values("è®°å½•æ—¶é—´")
    if product_data.empty:
        fig = go.Figure()
        fig.add_annotation(text="æ— æ­¤äº§å“æ•°æ®", x=0.5, y=0.5, showarrow=False, font=dict(size=16))
        fig.update_layout(title=f"{msku} å†å²åº“å­˜é¢„æµ‹", plot_bgcolor="#f8f9fa", height=400)
        return fig

    # 1. å®šä¹‰æ—¶é—´æ®µç³»æ•°ï¼ˆéœ€ä¸å…¶ä»–å‡½æ•°ä¿æŒä¸€è‡´ï¼‰
    TIME_PERIODS = [
        {"start": datetime(2025, 10, 15), "end": datetime(2025, 10, 31), "coefficient": 0.95},
        {"start": datetime(2025, 11, 1), "end": datetime(2025, 11, 15), "coefficient": 0.91},
        {"start": datetime(2025, 11, 16), "end": datetime(2025, 11, 30), "coefficient": 0.72},
        {"start": datetime(2025, 12, 1), "end": datetime(2025, 12, 31), "coefficient": 0.43}
    ]

    # 2. åˆ›å»ºå›¾è¡¨
    fig = go.Figure()

    # 3. ä¸ºæ¯ä¸ªè®°å½•æ—¶é—´æ·»åŠ é¢„æµ‹çº¿ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šåˆ†é˜¶æ®µè®¡ç®—ï¼‰
    for _, row in product_data.iterrows():
        record_date = row["è®°å½•æ—¶é—´"]
        label = record_date.strftime("%Y-%m-%d")
        base_avg = row["æ—¥å‡"] if row["æ—¥å‡"] > 0 else 0.1
        total_stock = row["å…¨éƒ¨æ€»åº“å­˜"]
        remaining_stock = total_stock
        end_date = END_DATE

        # åˆ†é˜¶æ®µè®¡ç®—è¯¥è®°å½•æ—¶é—´çš„é¢„æµ‹
        forecast_dates = []
        forecast_stock = []
        current_date = record_date

        while current_date <= end_date and remaining_stock > 0:
            # ç¡®å®šå½“å‰æ—¥æœŸçš„ç³»æ•°
            current_coeff = 1.0
            for period in TIME_PERIODS:
                if period["start"] <= current_date <= period["end"]:
                    current_coeff = period["coefficient"]
                    break

            # è®¡ç®—å½“å¤©é”€é‡å¹¶æ‰£å‡åº“å­˜
            daily_sales = base_avg * current_coeff
            remaining_stock = max(remaining_stock - daily_sales, 0)

            # è®°å½•æ•°æ®
            forecast_dates.append(current_date)
            forecast_stock.append(remaining_stock)

            # æ—¥æœŸ+1å¤©
            current_date += timedelta(days=1)

        # æ·»åŠ è¯¥è®°å½•æ—¶é—´çš„é¢„æµ‹çº¿
        fig.add_trace(go.Scatter(
            x=forecast_dates,
            y=forecast_stock,
            mode="lines",
            name=f"{label}ï¼ˆè®°å½•ï¼‰",
            line=dict(width=2)
        ))

    # 4. æ·»åŠ ç›®æ ‡æ—¥æœŸçº¿ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.add_vline(
        x=TARGET_DATE.timestamp() * 1000,
        line_dash="dash",
        line_color="#DC143C",
        annotation_text="ç›®æ ‡æ¶ˆè€—æ—¥æœŸ",
        annotation_position="top right",
        annotation_font=dict(color="#DC143C")
    )

    # 5. å›¾è¡¨å¸ƒå±€ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.update_layout(
        title=f"{msku} ä¸åŒè®°å½•æ—¶é—´çš„åº“å­˜é¢„æµ‹å¯¹æ¯”ï¼ˆå«åˆ†é˜¶æ®µç³»æ•°ï¼‰",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="å‰©ä½™åº“å­˜",
        plot_bgcolor="#f8f9fa",
        height=400,
        margin=dict(t=50, b=20, l=20, r=20),
        legend_title="è®°å½•æ—¶é—´"
    )

    # 6. æ¨ªåæ ‡è®¾ç½®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=30, label="30å¤©", step="day", stepmode="backward"),
                dict(count=1, label="1æœˆ", step="month", stepmode="backward"),
                dict(step="all", label="å…¨éƒ¨")
            ])
        ),
        type="date",
        tickformat="%Yå¹´%mæœˆ%dæ—¥",
        dtick=864000000,
        ticklabelmode="period"
    )

    return fig


# åœ¨render_stock_forecast_chartå‡½æ•°ä¸­ä¿®æ”¹ç›®æ ‡æ—¥æœŸçº¿
def render_stock_forecast_chart(data, msku):
    """æ¸²æŸ“å•ä¸ªMSKUçš„åº“å­˜é¢„æµ‹å›¾è¡¨ï¼ˆä»è®°å½•æ—¶é—´åˆ°2025å¹´12æœˆ31æ—¥ï¼Œå«åˆ†é˜¶æ®µç³»æ•°ï¼‰"""
    if data is None or data.empty:
        fig = go.Figure()
        fig.add_annotation(text="æ— æ•°æ®å¯å±•ç¤º", x=0.5, y=0.5, showarrow=False, font=dict(size=16))
        fig.update_layout(title=f"{msku} åº“å­˜é¢„æµ‹", plot_bgcolor="#f8f9fa", height=400)
        return fig

    row = data.iloc[0]
    start_date = row["è®°å½•æ—¶é—´"]  # è®°å½•æ—¶é—´
    end_date = END_DATE  # 2025å¹´12æœˆ31æ—¥
    base_avg = row["æ—¥å‡"] if row["æ—¥å‡"] > 0 else 0.1  # åŸºç¡€æ—¥å‡
    total_stock = row["å…¨éƒ¨æ€»åº“å­˜"]
    remaining_stock = total_stock

    # 1. å®šä¹‰æ—¶é—´æ®µç³»æ•°ï¼ˆéœ€ä¸load_and_preprocess_data_from_dfä¿æŒä¸€è‡´ï¼‰
    TIME_PERIODS = [
        {"start": datetime(2025, 10, 15), "end": datetime(2025, 10, 31), "coefficient": 0.95},
        {"start": datetime(2025, 11, 1), "end": datetime(2025, 11, 15), "coefficient": 0.91},
        {"start": datetime(2025, 11, 16), "end": datetime(2025, 11, 30), "coefficient": 0.72},
        {"start": datetime(2025, 12, 1), "end": datetime(2025, 12, 31), "coefficient": 0.43}
    ]

    # 2. åˆ†é˜¶æ®µè®¡ç®—å‰©ä½™åº“å­˜ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰
    forecast_dates = []
    forecast_stock = []
    current_date = start_date

    while current_date <= end_date and remaining_stock > 0:
        # ç¡®å®šå½“å‰æ—¥æœŸå¯¹åº”çš„ç³»æ•°
        current_coeff = 1.0  # é»˜è®¤ç³»æ•°1.0
        for period in TIME_PERIODS:
            if period["start"] <= current_date <= period["end"]:
                current_coeff = period["coefficient"]
                break

        # è®¡ç®—å½“å¤©çš„é”€é‡ï¼ˆåŸºç¡€æ—¥å‡Ã—å½“å‰ç³»æ•°ï¼‰
        daily_sales = base_avg * current_coeff
        # æ‰£å‡åº“å­˜ï¼ˆç¡®ä¿ä¸å°äº0ï¼‰
        remaining_stock = max(remaining_stock - daily_sales, 0)

        # è®°å½•æ—¥æœŸå’Œåº“å­˜
        forecast_dates.append(current_date)
        forecast_stock.append(remaining_stock)

        # æ—¥æœŸ+1å¤©
        current_date += timedelta(days=1)

    # 3. ç”ŸæˆæŠ˜çº¿å›¾ï¼ˆä½¿ç”¨åˆ†é˜¶æ®µè®¡ç®—çš„ç»“æœï¼‰
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=forecast_dates,
        y=forecast_stock,
        mode="lines+markers",
        line=dict(color="#4169E1", width=2),
        name="é¢„è®¡åº“å­˜ï¼ˆåˆ†é˜¶æ®µç³»æ•°ï¼‰"
    ))

    # 4. æ·»åŠ ç›®æ ‡æ—¥æœŸçº¿ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.add_vline(
        x=TARGET_DATE.timestamp() * 1000,  # è½¬æ¢ä¸ºæ¯«ç§’çº§æ—¶é—´æˆ³
        line_dash="dash",
        line_color="#DC143C",  # çº¢è‰²
        annotation_text="ç›®æ ‡æ¶ˆè€—æ—¥æœŸ",
        annotation_position="top right",
        annotation_font=dict(color="#DC143C")
    )

    # 5. æ·»åŠ æ—¶é—´æ®µç³»æ•°æ ‡æ³¨ï¼ˆå¯é€‰ï¼Œå¢å¼ºå¯è¯»æ€§ï¼‰
    for period in TIME_PERIODS:
        # åœ¨æ—¶é—´æ®µèµ·å§‹ä½ç½®æ·»åŠ ç³»æ•°æ ‡æ³¨
        fig.add_annotation(
            x=period["start"],
            y=max(forecast_stock) * 0.9,  # æ ‡æ³¨ä½ç½®åœ¨åº“å­˜å³°å€¼çš„90%å¤„
            text=f"{period['start'].strftime('%m-%d')}èµ·ç³»æ•°: {period['coefficient']}",
            showarrow=True,
            arrowhead=1,
            arrowcolor=STATUS_COLORS["ä½æ»é”€é£é™©"],
            font=dict(size=10, color=STATUS_COLORS["ä½æ»é”€é£é™©"])
        )

    # 6. å›¾è¡¨å¸ƒå±€ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.update_layout(
        title=f"{msku} åº“å­˜æ¶ˆè€—é¢„æµ‹ï¼ˆå«åˆ†é˜¶æ®µé”€é‡ç³»æ•°ï¼‰",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="å‰©ä½™åº“å­˜",
        plot_bgcolor="#f8f9fa",
        height=400,
        margin=dict(t=50, b=20, l=20, r=20)
    )

    # 7. æ¨ªåæ ‡è®¾ç½®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
    fig.update_xaxes(
        rangeslider_visible=True,
        rangeselector=dict(
            buttons=list([
                dict(count=30, label="30å¤©", step="day", stepmode="backward"),
                dict(count=1, label="1æœˆ", step="month", stepmode="backward"),
                dict(step="all", label="å…¨éƒ¨")
            ])
        ),
        type="date",
        tickformat="%Yå¹´%mæœˆ%dæ—¥",
        dtick=864000000,  # 10å¤©çš„æ¯«ç§’æ•°
        ticklabelmode="period"
    )

    return fig

# ------------------------------
# 3. ä¸»å‡½æ•°ï¼ˆé¡µé¢å¸ƒå±€ï¼‰
# ------------------------------
def main():
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "current_page" not in st.session_state:
        st.session_state.current_page = 1
    if "current_status_page" not in st.session_state:
        st.session_state.current_status_page = 1

    # ä¾§è¾¹æ å†…å®¹ï¼ˆå›ºå®šï¼‰
    with st.sidebar:
        st.title("ä¾§æ ä¿¡æ¯")
        from datetime import datetime  # æ­£ç¡®å¯¼å…¥æ–¹å¼
        # é¦–å…ˆç¡®ä¿å¯¼å…¥äº†éœ€è¦çš„ç±»
        from datetime import datetime, timedelta  # å…³é”®ï¼šå¯¼å…¥timedelta
        # æ˜¾ç¤ºæ—¥æœŸä¿¡æ¯
        # è®¡ç®—å½“å‘¨å‘¨ä¸€çš„æ—¥æœŸ
        today = datetime.now().date()
        # weekday()è¿”å›0-6ï¼Œå…¶ä¸­0æ˜¯å‘¨ä¸€ï¼Œ6æ˜¯å‘¨æ—¥
        # å¦‚æœä»Šå¤©æ˜¯å‘¨ä¸€ï¼Œç›´æ¥ä½¿ç”¨ä»Šå¤©ï¼›å¦åˆ™è®¡ç®—ä¸Šä¸€ä¸ªå‘¨ä¸€
        days_to_monday = today.weekday()  # è·ç¦»æœ¬å‘¨ä¸€çš„å¤©æ•°ï¼ˆ0è¡¨ç¤ºä»Šå¤©å°±æ˜¯å‘¨ä¸€ï¼‰
        monday_of_week = today - timedelta(days=days_to_monday)

        # æ˜¾ç¤ºå½“å‘¨å‘¨ä¸€ä¿¡æ¯
        st.info(f"å½“å‘¨å‘¨ä¸€ï¼š{monday_of_week.strftime('%Yå¹´%mæœˆ%dæ—¥')}")

        # æ˜¾ç¤ºç›®æ ‡æ—¥æœŸå’Œå‰©ä½™å¤©æ•°
        days_remaining = (TARGET_DATE.date() - monday_of_week).days
        st.info(f"ç›®æ ‡æ¶ˆè€—å®Œæˆæ—¥æœŸï¼š{TARGET_DATE.strftime('%Yå¹´%mæœˆ%dæ—¥')}")
        st.warning(f"è·ç¦»ç›®æ ‡æ—¥æœŸå‰©ä½™ï¼š{days_remaining}å¤©")
        # æ·»åŠ MSKUæ»é”€é£é™©åˆ†ç±»è¯´æ˜
        st.subheader("MSKUæ»é”€é£é™©åˆ†ç±»ï¼š")
        st.markdown("""
        - **å¥åº·**ï¼šé¢„è®¡æ€»åº“å­˜ç”¨å®Œæ—¶é—´â‰¤2025å¹´12æœˆ1æ—¥ï¼›
        - **ä½æ»é”€é£é™©**ï¼šé¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©åœ¨0-10å¤©å†…ï¼›
        - **ä¸­æ»é”€é£é™©**ï¼šé¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©10-20å¤©å†…ï¼›
        - **é«˜æ»é”€é£é™©**ï¼šé¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°>20å¤©ã€‚
        """)

        # æ³¨é‡Šæ‰æ–‡ä»¶ä¸Šä¼ éƒ¨åˆ†
        # st.subheader("æ•°æ®ä¸Šä¼ ")
        # uploaded_file = st.file_uploader("ä¸Šä¼ Excelæ–‡ä»¶", type=["xlsx"])

        # æ–°å¢ï¼šç›´æ¥è¯»å–GitHubä»“åº“ä¸­çš„æ•°æ®æ–‡ä»¶
        st.subheader("æ•°æ®åŠ è½½ä¸­...")
        try:
            # æ­£ç¡®çš„Rawæ ¼å¼é“¾æ¥
            data_url = "https://raw.githubusercontent.com/Jane-zzz-123/-/main/weekday.xlsx"

            # ä»URLè¯»å–æ•°æ®
            response = requests.get(data_url)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            excel_data = BytesIO(response.content)
            import pandas as pd  # å¯¼å…¥pandasåº“å¹¶å‘½åä¸ºpd

            # åªè¯»å–å­˜åœ¨çš„"å½“å‰æ•°æ®"sheet
            current_data = pd.read_excel(
                excel_data,
                sheet_name="å½“å‰æ•°æ®",
                engine='openpyxl'  # æ˜ç¡®æŒ‡å®šå¼•æ“
            )

            # ------------------------------
            # æ–°å¢ï¼šè°ƒç”¨é¢„å¤„ç†å‡½æ•°ï¼Œæ‰§è¡Œè®¡ç®—é€»è¾‘
            # ï¼ˆåŒ…æ‹¬ç”Ÿæˆ"çŠ¶æ€åˆ¤æ–­"ç­‰æ‰€æœ‰è¡ç”Ÿåˆ—ï¼‰
            # ------------------------------
            df = load_and_preprocess_data_from_df(current_data)  # å…³é”®ä¿®æ”¹ï¼šæ‰§è¡Œè®¡ç®—
            if df is None:  # å¤„ç†é¢„å¤„ç†å¤±è´¥çš„æƒ…å†µ
                st.error("æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                st.stop()

            # ------------------------------
            # æ–°å¢ï¼šæ ¹æ®ç”¨æˆ·æƒé™ç­›é€‰åº—é“º
            # ------------------------------
            allowed_stores = st.session_state.get("allowed_stores")
            if allowed_stores is not None:  # éç®¡ç†å‘˜ï¼ˆæœ‰åº—é“ºé™åˆ¶ï¼‰
                # ç­›é€‰dfä¸­"åº—é“º"åˆ—å±äºallowed_storesçš„è¡Œ
                df = df[df["åº—é“º"].isin(allowed_stores)].copy()
                # æ£€æŸ¥ç­›é€‰åæ˜¯å¦æœ‰æ•°æ®
                if df.empty:
                    st.error(f"æ‚¨æœ‰æƒé™çš„åº—é“ºï¼ˆ{', '.join(allowed_stores)}ï¼‰æ²¡æœ‰æ•°æ®")
                    st.stop()  # æ— æ•°æ®åˆ™åœæ­¢è¿è¡Œ

            st.success("æ•°æ®åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            st.error(f"æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}")
            # å¢åŠ è°ƒè¯•ä¿¡æ¯ï¼Œå¸®åŠ©ç¡®è®¤é—®é¢˜
            try:
                # å°è¯•è·å–æ–‡ä»¶ä¸­çš„æ‰€æœ‰sheetåç§°
                excel_data.seek(0)
                xl = pd.ExcelFile(excel_data, engine='openpyxl')
                st.error(f"Excelæ–‡ä»¶ä¸­å®é™…å­˜åœ¨çš„sheetï¼š{xl.sheet_names}")
            except:
                pass
            st.stop()  # åŠ è½½å¤±è´¥åˆ™åœæ­¢è¿è¡Œ

    # ä¸»å†…å®¹åŒºæ ‡é¢˜
    st.title("å¹´ä»½å“æ»é”€é£é™©åˆ†æä»ªè¡¨ç›˜")
    # ------------------------------
    # æ–°å¢ï¼šç³»æ•°ç¼–è¾‘åŠŸèƒ½ï¼ˆæ’å…¥æ­¤å¤„ï¼‰
    # ------------------------------
    # 1. åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ï¼ˆç”¨äºæ§åˆ¶ç¼–è¾‘è¡¨æ ¼æ˜¾ç¤º/éšè—ã€å­˜å‚¨ç¼–è¾‘åçš„æ•°æ®ï¼‰
    if "show_coefficient_editor" not in st.session_state:
        st.session_state.show_coefficient_editor = False
    if "edited_df" not in st.session_state:
        st.session_state.edited_df = None
    if "needs_recalculation" not in st.session_state:
        st.session_state.needs_recalculation = False

    # 2. ç³»æ•°ç¼–è¾‘å…¥å£æŒ‰é’®ï¼ˆæ”¾åœ¨ä»ªè¡¨ç›˜æ ‡é¢˜ä¸‹æ–¹ï¼Œæ˜¾çœ¼ä½ç½®ï¼‰
    col_edit, col_empty = st.columns([1, 4])  # å·¦å¯¹é½æŒ‰é’®
    with col_edit:
        if st.button("ğŸ” è¿è¥æ•°æ®è°ƒæ•´", key="edit_btn"):
            st.session_state.show_coefficient_editor = not st.session_state.show_coefficient_editor

    # 3. æ¸²æŸ“ç³»æ•°ç¼–è¾‘è¡¨æ ¼ï¼ˆä»…å½“å¼€å…³æ‰“å¼€æ—¶æ˜¾ç¤ºï¼‰
    if st.session_state.show_coefficient_editor:
        # å®šä¹‰ç¼–è¾‘è¡¨æ ¼æ‰€éœ€çš„åˆ—ï¼ˆæŒ‰æ‚¨çš„éœ€æ±‚ï¼‰
        edit_cols = [
            "åº—é“º", "è®°å½•æ—¶é—´", "MSKU", "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
            "10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"
        ]

        # 3.1 å‡†å¤‡ç¼–è¾‘æ•°æ®ï¼ˆä¼˜å…ˆç”¨å·²ç¼–è¾‘çš„æ•°æ®ï¼Œå¦åˆ™ç”¨åŸå§‹æ•°æ®ï¼‰
        if st.session_state.edited_df is not None:
            # ç¡®ä¿ç¼–è¾‘åçš„æ•°æ®åŒ…å«æ‰€æœ‰å¿…è¦åˆ—
            edited_data = st.session_state.edited_df[edit_cols].copy()
        else:
            # ä»åŸå§‹æ•°æ®ä¸­æå–ç¼–è¾‘åˆ—ï¼ŒæŒ‰MSKU+è®°å½•æ—¶é—´å»é‡ï¼ˆé¿å…é‡å¤è¡Œï¼‰
            edited_data = df[edit_cols].drop_duplicates(subset=["MSKU", "è®°å½•æ—¶é—´"]).copy()
            # ç¡®ä¿ç³»æ•°åˆ—ä¸ºæ•°å€¼ç±»å‹ï¼ˆé¿å…ç¼–è¾‘æ—¶å‡ºé”™ï¼‰
            coeff_cols = ["10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"]
            for col in coeff_cols:
                edited_data[col] = edited_data[col].astype(float)

        # 3.2 æ˜¾ç¤ºå¯ç¼–è¾‘è¡¨æ ¼ï¼ˆStreamlitåŸç”Ÿç¼–è¾‘ç»„ä»¶ï¼‰
        st.subheader("è¿è¥æ•°æ®è°ƒæ•´ï¼ˆæ—¥å‡+æ—¶é—´æ®µç³»æ•°ï¼‰")
        st.info("å¯ç›´æ¥ä¿®æ”¹è¡¨æ ¼æ•°æ®ï¼Œæˆ–ä¸‹è½½æ¨¡æ¿ç¼–è¾‘åä¸Šä¼ ï¼›ç¡®è®¤åçœ‹æ¿å°†é‡æ–°è®¡ç®—ç»“æœ")

        edited_data = st.data_editor(
            edited_data,
            num_rows="dynamic",  # å…è®¸è¿è¥å¢åˆ è¡Œ
            column_config={
                # ç³»æ•°åˆ—é™åˆ¶ï¼š0-2ä¹‹é—´ï¼Œæ­¥é•¿0.01ï¼ˆé¿å…ä¸åˆç†å€¼ï¼‰
                "10æœˆ15-31æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01, format="%.2f"),
                "11æœˆ1-15æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01, format="%.2f"),
                "11æœˆ16-30æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01, format="%.2f"),
                "12æœˆ1-31æ—¥ç³»æ•°": st.column_config.NumberColumn(min_value=0, max_value=2, step=0.01, format="%.2f"),
                # æ—¥å‡åˆ—é™åˆ¶ï¼šéè´Ÿï¼ˆé”€é‡ä¸èƒ½ä¸ºè´Ÿï¼‰
                "æ—¥å‡": st.column_config.NumberColumn(min_value=0, format="%.2f"),
                "7å¤©æ—¥å‡": st.column_config.NumberColumn(min_value=0, format="%.2f"),
                "14å¤©æ—¥å‡": st.column_config.NumberColumn(min_value=0, format="%.2f"),
                "28å¤©æ—¥å‡": st.column_config.NumberColumn(min_value=0, format="%.2f"),
                # æ—¥æœŸåˆ—æ ¼å¼ä¼˜åŒ–
                "è®°å½•æ—¶é—´": st.column_config.DateColumn(format="YYYY-MM-DD"),
            },
            use_container_width=True,
            key="data_editor"
        )

        # 3.3 ä¸‹è½½åŠŸèƒ½ï¼ˆä¸‹è½½å½“å‰ç¼–è¾‘çš„è¡¨æ ¼ä½œä¸ºæ¨¡æ¿/å¤‡ä»½ï¼‰
        csv = edited_data.to_csv(index=False, encoding="utf-8-sig")
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å½“å‰æ•°æ®",
            data=csv,
            file_name=f"è¿è¥æ•°æ®è°ƒæ•´æ¨¡æ¿_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv",
            key="download_edit"
        )

        # 3.4 ä¸Šä¼ åŠŸèƒ½ï¼ˆæ”¯æŒä¸Šä¼ ç¼–è¾‘åçš„è¡¨æ ¼ï¼‰
        uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šä¼ ä¿®æ”¹åçš„è¡¨æ ¼", type=["csv", "xlsx"], key="upload_edit")
        if uploaded_file:
            try:
                # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
                if uploaded_file.name.endswith(".csv"):
                    uploaded_df = pd.read_csv(uploaded_file)
                else:
                    uploaded_df = pd.read_excel(uploaded_file, engine="openpyxl")
                # æ ¡éªŒåˆ—æ˜¯å¦å®Œæ•´
                missing_cols = [col for col in edit_cols if col not in uploaded_df.columns]
                if missing_cols:
                    st.error(f"ä¸Šä¼ æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ï¼š{', '.join(missing_cols)}")
                else:
                    # æ ¼å¼è½¬æ¢ï¼ˆç¡®ä¿æ—¥æœŸå’Œæ•°å€¼ç±»å‹æ­£ç¡®ï¼‰
                    uploaded_df["è®°å½•æ—¶é—´"] = pd.to_datetime(uploaded_df["è®°å½•æ—¶é—´"]).dt.normalize()
                    for col in coeff_cols + ["æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡"]:
                        uploaded_df[col] = pd.to_numeric(uploaded_df[col], errors="coerce").fillna(0)
                    # æ›´æ–°ç¼–è¾‘åŒºæ•°æ®
                    edited_data = uploaded_df[edit_cols].copy()
                    st.success("ä¸Šä¼ æˆåŠŸï¼å·²æ›´æ–°ç¼–è¾‘åŒºæ•°æ®")
            except Exception as e:
                st.error(f"ä¸Šä¼ å¤±è´¥ï¼š{str(e)}")

        # 3.5 ç¡®è®¤æŒ‰é’®ï¼ˆä¿å­˜ç¼–è¾‘æ•°æ®å¹¶è§¦å‘é‡æ–°è®¡ç®—ï¼‰
        if st.button("âœ… ç¡®è®¤ä¿®æ”¹å¹¶åˆ·æ–°çœ‹æ¿", key="confirm_edit"):
            # ä¿å­˜ç¼–è¾‘åçš„æ•°æ®åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.edited_df = edited_data
            # æ ‡è®°éœ€è¦é‡æ–°è®¡ç®—
            st.session_state.needs_recalculation = True
            # å…³é—­ç¼–è¾‘è¡¨æ ¼
            st.session_state.show_coefficient_editor = False
            st.success("ä¿®æ”¹å·²ä¿å­˜ï¼Œçœ‹æ¿æ­£åœ¨é‡æ–°è®¡ç®—...")
            st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ï¼ŒåŠ è½½æ–°æ•°æ®

    # åˆå§‹åŒ–session_stateå­˜å‚¨ç­›é€‰çŠ¶æ€
    if "filter_status" not in st.session_state:
        st.session_state.filter_status = None
    if "current_page" not in st.session_state:
        st.session_state.current_page = 1
    # æ–°å¢ï¼šåº”ç”¨ç¼–è¾‘åçš„æ•°æ®ï¼ˆå…³é”®ï¼æ›¿æ¢åŸå§‹dfï¼‰
    # ------------------------------
    if st.session_state.needs_recalculation and st.session_state.edited_df is not None:
        # åˆå¹¶åŸå§‹æ•°æ®ä¸ç¼–è¾‘åçš„æ•°æ®ï¼ˆæŒ‰MSKU+è®°å½•æ—¶é—´åŒ¹é…ï¼‰
        df = df.merge(
            st.session_state.edited_df,
            on=["åº—é“º", "è®°å½•æ—¶é—´", "MSKU"],
            how="left",
            suffixes=("_original", "_edited")
        )
        # ç”¨ç¼–è¾‘åçš„æ•°æ®è¦†ç›–åŸå§‹æ•°æ®ï¼ˆä¼˜å…ˆä¿ç•™ç¼–è¾‘å€¼ï¼Œç¼ºå¤±åˆ™ç”¨åŸå§‹å€¼ï¼‰
        update_cols = ["æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                      "10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"]
        for col in update_cols:
            df[col] = df[f"{col}_edited"].fillna(df[f"{col}_original"])
        # åˆ é™¤ä¸´æ—¶åˆ—
        df = df.drop(columns=[c for c in df.columns if c.endswith(("_original", "_edited"))])
        # é‡æ–°æ‰§è¡Œé¢„å¤„ç†è®¡ç®—ï¼ˆåŸºäºç¼–è¾‘åçš„æ•°æ®ï¼‰
        df = load_and_preprocess_data_from_df(df)
        # é‡ç½®é‡æ–°è®¡ç®—æ ‡è®°
        st.session_state.needs_recalculation = False

    # è·å–æ‰€æœ‰è®°å½•æ—¶é—´å¹¶æ’åº
    all_dates = sorted(df["è®°å½•æ—¶é—´"].unique())
    latest_date = all_dates[-1] if all_dates else None

    # ------------------------------
    # ç¬¬ä¸€éƒ¨åˆ†ï¼šæ•´ä½“é£é™©åˆ†æ
    # ------------------------------
    st.header("ä¸€ã€æ•´ä½“é£é™©åˆ†æ")

    # è®°å½•æ—¶é—´ç­›é€‰å™¨
    selected_date = st.selectbox(
        "é€‰æ‹©è®°å½•æ—¶é—´",
        options=all_dates,
        index=len(all_dates) - 1 if all_dates else 0,
        format_func=lambda x: x.strftime("%Yå¹´%mæœˆ%dæ—¥")
    )

    # è·å–å½“å‰å‘¨å’Œä¸Šå‘¨æ•°æ®
    current_data = get_week_data(df, selected_date)
    prev_data = get_previous_week_data(df, selected_date)

    st.subheader("1 åº—é“ºæ•´ä½“åˆ†æ")
    if current_data is not None and not current_data.empty:
        stores = sorted(current_data["åº—é“º"].unique())
        selected_store = st.selectbox("é€‰æ‹©åº—é“ºè¿›è¡Œåˆ†æ", options=stores)

        if selected_store:
            # å½“å‰åº—é“ºæ•°æ®ä¸æŒ‡æ ‡
            store_current_data = current_data[current_data["åº—é“º"] == selected_store].copy()
            store_current_metrics = calculate_status_metrics(store_current_data)

            # è·å–ä¸Šå‘¨åº—é“ºæ•°æ®ä¸æŒ‡æ ‡ï¼ˆä¿®æ”¹ï¼šè¿”å›å®Œæ•´æ•°æ®+æ»é”€åº“å­˜ï¼Œç”¨äºåç»­å¯¹æ¯”ï¼‰
            def get_store_last_week_metrics():
                from datetime import timedelta
                current_date = pd.to_datetime(store_current_data["è®°å½•æ—¶é—´"].iloc[0])
                last_week_start = current_date - timedelta(days=14)
                last_week_end = current_date - timedelta(days=7)

                if 'prev_data' in locals() and prev_data is not None and not prev_data.empty:
                    prev_data_filtered = prev_data[prev_data["åº—é“º"] == selected_store].copy()
                    prev_data_filtered['è®°å½•æ—¶é—´'] = pd.to_datetime(prev_data_filtered['è®°å½•æ—¶é—´'])
                    last_week_data = prev_data_filtered[
                        (prev_data_filtered['è®°å½•æ—¶é—´'] >= last_week_start) &
                        (prev_data_filtered['è®°å½•æ—¶é—´'] <= last_week_end)
                        ]
                    if not last_week_data.empty:
                        # è®¡ç®—ä¸Šå‘¨çŠ¶æ€æŒ‡æ ‡+æ€»æ»é”€åº“å­˜
                        metrics = calculate_status_metrics(last_week_data)
                        metrics["æ€»æ»é”€åº“å­˜"] = last_week_data[
                            "æ€»æ»é”€åº“å­˜"].sum() if "æ€»æ»é”€åº“å­˜" in last_week_data.columns else 0
                        return metrics, last_week_data  # æ–°å¢è¿”å›ä¸Šå‘¨åŸå§‹æ•°æ®
                # æ— æ•°æ®æ—¶è¿”å›é»˜è®¤å€¼ï¼ˆå«æ€»æ»é”€åº“å­˜ï¼‰
                return {
                    "æ€»MSKUæ•°": 0, "å¥åº·": 0, "ä½æ»é”€é£é™©": 0, "ä¸­æ»é”€é£é™©": 0, "é«˜æ»é”€é£é™©": 0,
                    "æ€»æ»é”€åº“å­˜": 0
                }, None

            # è°ƒç”¨ä¿®æ”¹ï¼šæ¥æ”¶ä¸Šå‘¨æŒ‡æ ‡+åŸå§‹æ•°æ®
            store_last_week_metrics, last_week_data = get_store_last_week_metrics()

            # æ–°å¢1ï¼šè®¡ç®—çŠ¶æ€å˜åŒ–ï¼ˆå˜å¥½/ä¸å˜/å˜å·®çš„MSKUæ•°ï¼‰
            status_change = {
                "å¥åº·": {"æ”¹å–„": 0, "ä¸å˜": 0, "æ¶åŒ–": 0},
                "ä½æ»é”€é£é™©": {"æ”¹å–„": 0, "ä¸å˜": 0, "æ¶åŒ–": 0},
                "ä¸­æ»é”€é£é™©": {"æ”¹å–„": 0, "ä¸å˜": 0, "æ¶åŒ–": 0},
                "é«˜æ»é”€é£é™©": {"æ”¹å–„": 0, "ä¸å˜": 0, "æ¶åŒ–": 0}
            }
            # çŠ¶æ€ä¸¥é‡ç¨‹åº¦æ’åºï¼ˆç”¨äºåˆ¤æ–­å˜åŒ–æ–¹å‘ï¼šå¥åº· < ä½é£é™© < ä¸­é£é™© < é«˜é£é™©ï¼‰
            status_severity = {"å¥åº·": 0, "ä½æ»é”€é£é™©": 1, "ä¸­æ»é”€é£é™©": 2, "é«˜æ»é”€é£é™©": 3}

            # åŒ¹é…MSKUè®¡ç®—çŠ¶æ€å˜åŒ–
            if last_week_data is not None and not last_week_data.empty and "MSKU" in store_current_data.columns:
                merged_data = pd.merge(
                    store_current_data[["MSKU", "çŠ¶æ€åˆ¤æ–­"]],
                    last_week_data[["MSKU", "çŠ¶æ€åˆ¤æ–­"]],
                    on="MSKU",
                    suffixes=("_current", "_prev"),
                    how="inner"
                )
                for _, row in merged_data.iterrows():
                    current_status = row["çŠ¶æ€åˆ¤æ–­_current"]
                    prev_status = row["çŠ¶æ€åˆ¤æ–­_prev"]
                    if current_status not in status_severity or prev_status not in status_severity:
                        continue
                    if current_status == prev_status:
                        status_change[current_status]["ä¸å˜"] += 1
                    elif status_severity[current_status] < status_severity[prev_status]:
                        status_change[current_status]["æ”¹å–„"] += 1  # å½“å‰çŠ¶æ€æ›´è½»=å˜å¥½
                    else:
                        status_change[current_status]["æ¶åŒ–"] += 1  # å½“å‰çŠ¶æ€æ›´é‡=å˜å·®

            # è®¡ç®—å¯¹æ¯”æŒ‡æ ‡ï¼ˆä¿®æ”¹ï¼šç™¾åˆ†æ¯”ä¿ç•™ä¸¤ä½å°æ•°ï¼‰
            store_metrics = {}
            for metric in ["æ€»MSKUæ•°", "å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]:
                current = int(store_current_metrics[metric])
                last_week = int(store_last_week_metrics[metric])
                diff = current - last_week
                pct = (diff / last_week) * 100 if last_week != 0 else 0.0
                store_metrics[metric] = {
                    "current": current,
                    "last_week": last_week,
                    "diff": diff,
                    "pct": round(pct, 2)  # åŸ1ä½â†’2ä½å°æ•°
                }

            # æ–°å¢2ï¼šç”Ÿæˆæ»é”€åº“å­˜å¯¹æ¯”æ–‡æœ¬ï¼ˆä¿ç•™ä¸¤ä½å°æ•°+ç¯æ¯”ç™¾åˆ†æ¯”ï¼‰
            def get_overstock_compare_text(current_overstock, last_week_overstock, status=None):
                # å¤„ç†æ•°å€¼æ ¼å¼ï¼ˆä¿ç•™ä¸¤ä½å°æ•°ï¼‰
                current = round(float(current_overstock), 2)
                last_week = round(float(last_week_overstock), 2)

                if last_week == 0:
                    return f"<br><span style='color:#666; font-size:0.8em;'>{status + ' ' if status else ''}æ€»æ»é”€åº“å­˜: {current:.2f}</span>"

                # è®¡ç®—å·®å¼‚å’Œç¯æ¯”
                diff = current - last_week
                trend = "â†‘" if diff > 0 else "â†“" if diff < 0 else "â†’"
                color = "#DC143C" if diff > 0 else "#2E8B57" if diff < 0 else "#666"
                pct = (diff / last_week) * 100 if last_week != 0 else 0.0
                pct_text = f"{abs(pct):.2f}%"

                return f"<br><span style='color:{color}; font-size:0.8em;'>{status + ' ' if status else ''}æ€»æ»é”€åº“å­˜: {current:.2f} ({trend}{abs(diff):.2f} {pct_text})</span>"

            # æ–°å¢3ï¼šç”ŸæˆçŠ¶æ€å˜åŒ–æ–‡æœ¬ï¼ˆé¢œè‰²åŒºåˆ†å˜å¥½/ä¸å˜/å˜å·®ï¼‰
            def get_status_change_text(status):
                changes = status_change[status]
                total = changes["æ”¹å–„"] + changes["ä¸å˜"] + changes["æ¶åŒ–"]
                if total == 0:
                    return "<br><span style='color:#666; font-size:0.8em;'>çŠ¶æ€å˜åŒ–: æ— æ•°æ®</span>"

                return f"""<br>
                <span style='color:#2E8B57; font-size:0.8em;'>æ”¹å–„: {changes['æ”¹å–„']}</span> | 
                <span style='color:#666; font-size:0.8em;'>ä¸å˜: {changes['ä¸å˜']}</span> | 
                <span style='color:#DC143C; font-size:0.8em;'>æ¶åŒ–: {changes['æ¶åŒ–']}</span>
                """

            # ç”Ÿæˆå¯¹æ¯”æ–‡æœ¬ï¼ˆä¿®æ”¹ï¼šç™¾åˆ†æ¯”æ˜¾ç¤ºä¸¤ä½å°æ•°ï¼‰
            def get_compare_text(metric_data, metric_name):
                if metric_data["last_week"] == 0:
                    return "<br><span style='color:#666; font-size:0.8em;'>æ— ä¸Šå‘¨æ•°æ®</span>"

                trend = "â†‘" if metric_data["diff"] > 0 else "â†“" if metric_data["diff"] < 0 else "â†’"
                color = "#DC143C" if metric_data["diff"] > 0 else "#2E8B57" if metric_data["diff"] < 0 else "#666"
                pct_text = f"{abs(metric_data['pct']):.2f}%"  # åŸ1ä½â†’2ä½å°æ•°

                if metric_name == "æ€»MSKUæ•°":
                    return f"<br><span style='color:{color}; font-size:0.8em;'>{trend} ä¸Šå‘¨{metric_data['last_week']}ï¼Œå˜åŒ–{metric_data['diff']} ({pct_text})</span>"
                else:
                    status = "ä¸Šå‡" if metric_data["diff"] > 0 else "ä¸‹é™" if metric_data["diff"] < 0 else "æ— å˜åŒ–"
                    return f"<br><span style='color:{color}; font-size:0.8em;'>{trend} ä¸Šå‘¨{metric_data['last_week']}ï¼Œ{status}{abs(metric_data['diff'])} ({pct_text})</span>"

            # æ˜¾ç¤ºå¸¦ä¸Šå‘¨å¯¹æ¯”çš„æŒ‡æ ‡å¡ç‰‡ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šæ–°å¢æ»é”€åº“å­˜+çŠ¶æ€å˜åŒ–ï¼‰
            cols = st.columns(5)
            with cols[0]:
                data = store_metrics["æ€»MSKUæ•°"]
                compare_text = get_compare_text(data, "æ€»MSKUæ•°")
                # æ€»æ»é”€åº“å­˜ï¼ˆå…¨çŠ¶æ€åˆè®¡ï¼‰
                total_overstock = store_current_data[
                    "æ€»æ»é”€åº“å­˜"].sum() if "æ€»æ»é”€åº“å­˜" in store_current_data.columns else 0
                last_week_total_overstock = store_last_week_metrics.get("æ€»æ»é”€åº“å­˜", 0)
                overstock_text = get_overstock_compare_text(total_overstock, last_week_total_overstock)

                render_metric_card(
                    f"{selected_store} æ€»MSKUæ•°{compare_text}{overstock_text}",
                    data["current"],
                    data["diff"],
                    data["pct"],
                    "#000000"
                )
            with cols[1]:
                data = store_metrics["å¥åº·"]
                compare_text = get_compare_text(data, "å¥åº·")
                # å¥åº·çŠ¶æ€ä¸“å±æ»é”€åº“å­˜
                healthy_overstock = store_current_data[store_current_data["çŠ¶æ€åˆ¤æ–­"] == "å¥åº·"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            "çŠ¶æ€åˆ¤æ–­" in store_current_data.columns and "æ€»æ»é”€åº“å­˜" in store_current_data.columns) else 0
                last_week_healthy_overstock = last_week_data[last_week_data["çŠ¶æ€åˆ¤æ–­"] == "å¥åº·"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            last_week_data is not None and "çŠ¶æ€åˆ¤æ–­" in last_week_data.columns and "æ€»æ»é”€åº“å­˜" in last_week_data.columns) else 0
                overstock_text = get_overstock_compare_text(healthy_overstock, last_week_healthy_overstock,
                                                            status="å¥åº·")
                # çŠ¶æ€å˜åŒ–æ–‡æœ¬
                change_text = get_status_change_text("å¥åº·")

                render_metric_card(
                    f"{selected_store} å¥åº·{compare_text}{overstock_text}{change_text}",
                    data["current"],
                    data["diff"],
                    data["pct"],
                    STATUS_COLORS["å¥åº·"]
                )
            with cols[2]:
                data = store_metrics["ä½æ»é”€é£é™©"]
                compare_text = get_compare_text(data, "ä½æ»é”€é£é™©")
                # ä½é£é™©ä¸“å±æ»é”€åº“å­˜
                low_risk_overstock = store_current_data[store_current_data["çŠ¶æ€åˆ¤æ–­"] == "ä½æ»é”€é£é™©"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            "çŠ¶æ€åˆ¤æ–­" in store_current_data.columns and "æ€»æ»é”€åº“å­˜" in store_current_data.columns) else 0
                last_week_low_risk_overstock = last_week_data[last_week_data["çŠ¶æ€åˆ¤æ–­"] == "ä½æ»é”€é£é™©"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            last_week_data is not None and "çŠ¶æ€åˆ¤æ–­" in last_week_data.columns and "æ€»æ»é”€åº“å­˜" in last_week_data.columns) else 0
                overstock_text = get_overstock_compare_text(low_risk_overstock, last_week_low_risk_overstock,
                                                            status="ä½é£é™©")
                # çŠ¶æ€å˜åŒ–æ–‡æœ¬
                change_text = get_status_change_text("ä½æ»é”€é£é™©")

                render_metric_card(
                    f"{selected_store} ä½æ»é”€é£é™©{compare_text}{overstock_text}{change_text}",
                    data["current"],
                    data["diff"],
                    data["pct"],
                    STATUS_COLORS["ä½æ»é”€é£é™©"]
                )
            with cols[3]:
                data = store_metrics["ä¸­æ»é”€é£é™©"]
                compare_text = get_compare_text(data, "ä¸­æ»é”€é£é™©")
                # ä¸­é£é™©ä¸“å±æ»é”€åº“å­˜
                mid_risk_overstock = store_current_data[store_current_data["çŠ¶æ€åˆ¤æ–­"] == "ä¸­æ»é”€é£é™©"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            "çŠ¶æ€åˆ¤æ–­" in store_current_data.columns and "æ€»æ»é”€åº“å­˜" in store_current_data.columns) else 0
                last_week_mid_risk_overstock = last_week_data[last_week_data["çŠ¶æ€åˆ¤æ–­"] == "ä¸­æ»é”€é£é™©"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            last_week_data is not None and "çŠ¶æ€åˆ¤æ–­" in last_week_data.columns and "æ€»æ»é”€åº“å­˜" in last_week_data.columns) else 0
                overstock_text = get_overstock_compare_text(mid_risk_overstock, last_week_mid_risk_overstock,
                                                            status="ä¸­é£é™©")
                # çŠ¶æ€å˜åŒ–æ–‡æœ¬
                change_text = get_status_change_text("ä¸­æ»é”€é£é™©")

                render_metric_card(
                    f"{selected_store} ä¸­æ»é”€é£é™©{compare_text}{overstock_text}{change_text}",
                    data["current"],
                    data["diff"],
                    data["pct"],
                    STATUS_COLORS["ä¸­æ»é”€é£é™©"]
                )
            with cols[4]:
                data = store_metrics["é«˜æ»é”€é£é™©"]
                compare_text = get_compare_text(data, "é«˜æ»é”€é£é™©")
                # é«˜é£é™©ä¸“å±æ»é”€åº“å­˜
                high_risk_overstock = store_current_data[store_current_data["çŠ¶æ€åˆ¤æ–­"] == "é«˜æ»é”€é£é™©"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            "çŠ¶æ€åˆ¤æ–­" in store_current_data.columns and "æ€»æ»é”€åº“å­˜" in store_current_data.columns) else 0
                last_week_high_risk_overstock = last_week_data[last_week_data["çŠ¶æ€åˆ¤æ–­"] == "é«˜æ»é”€é£é™©"][
                    "æ€»æ»é”€åº“å­˜"].sum() if (
                            last_week_data is not None and "çŠ¶æ€åˆ¤æ–­" in last_week_data.columns and "æ€»æ»é”€åº“å­˜" in last_week_data.columns) else 0
                overstock_text = get_overstock_compare_text(high_risk_overstock, last_week_high_risk_overstock,
                                                            status="é«˜é£é™©")
                # çŠ¶æ€å˜åŒ–æ–‡æœ¬
                change_text = get_status_change_text("é«˜æ»é”€é£é™©")

                render_metric_card(
                    f"{selected_store} é«˜æ»é”€é£é™©{compare_text}{overstock_text}{change_text}",
                    data["current"],
                    data["diff"],
                    data["pct"],
                    STATUS_COLORS["é«˜æ»é”€é£é™©"]
                )

            # å›¾è¡¨éƒ¨åˆ†ï¼šä¿®æ”¹ä¸ºã€Œä¸€è¡Œä¸‰åˆ—ï¼ˆçŠ¶æ€åˆ†å¸ƒ+çŠ¶æ€å æ¯”+çŠ¶æ€å˜åŒ–ï¼‰+ ä¸‹æ–¹ç»„åˆå›¾ã€å¸ƒå±€ï¼ˆä¿®å¤å›¾ä¾‹æ–¹å‘å‚æ•°é”™è¯¯ï¼‰
            # 1. ç¬¬ä¸€è¡Œï¼šä¸‰åˆ—å¸ƒå±€
            col1, col2, col3 = st.columns(3)

            # 1.1 ç¬¬ä¸€åˆ—ï¼šåŸçŠ¶æ€åˆ†å¸ƒæŸ±çŠ¶å›¾ï¼ˆä¿æŒä¸å˜ï¼‰
            with col1:
                status_data = pd.DataFrame({
                    "çŠ¶æ€": ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"],
                    "MSKUæ•°": [store_current_metrics[stat] for stat in
                               ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]]
                })

                fig_status = px.bar(
                    status_data,
                    x="çŠ¶æ€",
                    y="MSKUæ•°",
                    color="çŠ¶æ€",
                    color_discrete_map=STATUS_COLORS,
                    title=f"{selected_store} çŠ¶æ€åˆ†å¸ƒ",
                    text="MSKUæ•°",
                    height=400
                )

                fig_status.update_traces(
                    textposition="outside",
                    textfont=dict(size=12, weight="bold"),
                    marker=dict(line=dict(color="#fff", width=1))
                )

                fig_status.update_layout(
                    xaxis_title="é£é™©çŠ¶æ€",
                    yaxis_title="MSKUæ•°é‡",
                    showlegend=True,
                    plot_bgcolor="#f8f9fa",
                    margin=dict(t=50, b=20, l=20, r=20)
                )

                st.plotly_chart(fig_status, use_container_width=True)

            # 1.2 ç¬¬äºŒåˆ—ï¼šçŠ¶æ€åˆ¤æ–­é¥¼å›¾ï¼ˆä¿æŒä¸å˜ï¼‰
            with col2:
                pie_data = pd.DataFrame({
                    "çŠ¶æ€": ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"],
                    "MSKUæ•°": [store_current_metrics[stat] for stat in
                               ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]]
                })
                total_msku = pie_data["MSKUæ•°"].sum()
                pie_data["å æ¯”(%)"] = pie_data["MSKUæ•°"].apply(
                    lambda x: round((x / total_msku) * 100, 1) if total_msku != 0 else 0.0
                )
                pie_data["è‡ªå®šä¹‰æ ‡ç­¾"] = pie_data.apply(
                    lambda row: f"{row['çŠ¶æ€']}<br>{row['MSKUæ•°']}ä¸ª<br>({row['å æ¯”(%)']}%)",
                    axis=1
                )

                fig_pie = px.pie(
                    pie_data,
                    values="MSKUæ•°",
                    names="çŠ¶æ€",
                    color="çŠ¶æ€",
                    color_discrete_map=STATUS_COLORS,
                    title=f"{selected_store} çŠ¶æ€å æ¯”",
                    height=400,
                    labels={"MSKUæ•°": "MSKUæ•°é‡"}
                )

                fig_pie.update_traces(
                    text=pie_data["è‡ªå®šä¹‰æ ‡ç­¾"],
                    textinfo="text",
                    textfont=dict(size=10, weight="bold"),
                    hovertemplate="%{label}: %{value}ä¸ª (%{percent:.1%})"
                )

                fig_pie.update_layout(
                    showlegend=True,
                    legend_title="é£é™©çŠ¶æ€",
                    plot_bgcolor="#f8f9fa",
                    margin=dict(t=50, b=20, l=20, r=20)
                )

                st.plotly_chart(fig_pie, use_container_width=True)

            # 1.3 ç¬¬ä¸‰åˆ—ï¼šç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–æŸ±å½¢å›¾ï¼ˆä¿æŒä¸å˜ï¼‰
            with col3:
                change_data = pd.DataFrame({
                    "çŠ¶æ€": ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"],
                    "æœ¬å‘¨MSKUæ•°": [store_current_metrics[stat] for stat in
                                   ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]],
                    "ä¸Šå‘¨MSKUæ•°": [store_last_week_metrics[stat] for stat in
                                   ["å¥åº·", "ä½æ»é”€é£é™©", "ä¸­æ»é”€é£é™©", "é«˜æ»é”€é£é™©"]]
                })
                change_data_long = pd.melt(
                    change_data,
                    id_vars="çŠ¶æ€",
                    value_vars=["æœ¬å‘¨MSKUæ•°", "ä¸Šå‘¨MSKUæ•°"],
                    var_name="å‘¨æœŸ",
                    value_name="MSKUæ•°"
                )

                fig_change = px.bar(
                    change_data_long,
                    x="çŠ¶æ€",
                    y="MSKUæ•°",
                    color="å‘¨æœŸ",
                    barmode="group",
                    color_discrete_map={"æœ¬å‘¨MSKUæ•°": "#2E86AB", "ä¸Šå‘¨MSKUæ•°": "#A23B72"},
                    title=f"{selected_store} çŠ¶æ€å˜åŒ–å¯¹æ¯”",
                    height=400,
                    text="MSKUæ•°"
                )

                fig_change.update_traces(
                    textposition="outside",
                    textfont=dict(size=10, weight="bold"),
                    marker=dict(line=dict(color="#fff", width=1))
                )

                fig_change.update_layout(
                    xaxis_title="é£é™©çŠ¶æ€",
                    yaxis_title="MSKUæ•°é‡",
                    showlegend=True,
                    legend_title="å‘¨æœŸ",
                    plot_bgcolor="#f8f9fa",
                    margin=dict(t=50, b=20, l=20, r=20)
                )

                st.plotly_chart(fig_change, use_container_width=True)
            if df is not None and not df.empty and selected_store:
                # è·å–å½“å‰é€‰ä¸­åº—é“ºçš„å½“å‰å‘¨æœŸæ•°æ®ï¼ˆç­›é€‰åº—é“ºï¼‰
                current_week_full_data = get_week_data(df, selected_date)
                current_week_store_data = current_week_full_data[
                    current_week_full_data["åº—é“º"] == selected_store] if current_week_full_data is not None else None

                # è·å–å½“å‰é€‰ä¸­åº—é“ºçš„ä¸Šä¸€å‘¨æœŸæ•°æ®ï¼ˆç­›é€‰åº—é“ºï¼‰
                previous_week_full_data = get_previous_week_data(df, selected_date)
                previous_week_store_data = previous_week_full_data[
                    previous_week_full_data["åº—é“º"] == selected_store] if previous_week_full_data is not None else None

                # åˆ›å»ºåº—é“ºçº§åˆ«çš„æ±‡æ€»è¡¨æ•°æ®
                store_summary_df = create_risk_summary_table(current_week_store_data, previous_week_store_data)

                # æ¸²æŸ“åº—é“ºçº§åˆ«çš„æ±‡æ€»è¡¨
                render_risk_summary_table(store_summary_df)

            # 2. ç¬¬äºŒéƒ¨åˆ†ï¼šä¸‹æ–¹ç»„åˆå›¾ï¼ˆä¿®å¤å›¾ä¾‹æ–¹å‘å‚æ•°ï¼‰
            st.subheader(f"{selected_store} åº“å­˜æ¶ˆè€—å¤©æ•°åˆ†å¸ƒï¼ˆMSKUæ•°+æ€»æ»é”€åº“å­˜ï¼‰")
            today = pd.to_datetime(store_current_data["è®°å½•æ—¶é—´"].iloc[0])
            days_to_target = (TARGET_DATE - today).days

            # 2.1 æ•°æ®é¢„å¤„ç†
            valid_days = store_current_data["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°"].clip(lower=0)
            max_days = valid_days.max() if not valid_days.empty else 0
            bin_width = 20
            num_bins = int((max_days + bin_width - 1) // bin_width)
            bins = [i * bin_width for i in range(num_bins + 1)]
            bin_labels = [f"{bins[i]}-{bins[i + 1]}" for i in range(len(bins) - 1)]

            # 2.2 è®¡ç®—å¤©æ•°åŒºé—´å¯¹åº”çš„MSKUæ•°é‡å’Œæ€»æ»é”€åº“å­˜
            msku_count = pd.cut(
                valid_days,
                bins=bins,
                labels=bin_labels,
                include_lowest=True
            ).value_counts().sort_index()

            temp_df = store_current_data[["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "æ€»æ»é”€åº“å­˜"]].copy()
            temp_df["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°"] = temp_df["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°"].clip(lower=0)
            temp_df["å¤©æ•°åŒºé—´"] = pd.cut(
                temp_df["é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°"],
                bins=bins,
                labels=bin_labels,
                include_lowest=True
            )
            overstock_sum = temp_df.groupby("å¤©æ•°åŒºé—´")["æ€»æ»é”€åº“å­˜"].sum().sort_index()

            # 2.3 åˆå¹¶æ•°æ®
            combined_data = pd.DataFrame({
                "å¤©æ•°åŒºé—´": bin_labels,
                "MSKUæ•°é‡": [msku_count.get(label, 0) for label in bin_labels],
                "æ€»æ»é”€åº“å­˜": [overstock_sum.get(label, 0.0) for label in bin_labels]
            })

            # 2.4 åˆ›å»ºç»„åˆå›¾
            fig_combined = px.bar(
                combined_data,
                x="å¤©æ•°åŒºé—´",
                y="æ€»æ»é”€åº“å­˜",
                color_discrete_sequence=["#F18F01"],
                title="åº“å­˜æ¶ˆè€—å¤©æ•° vs æ€»æ»é”€åº“å­˜",
                height=400,
                text="æ€»æ»é”€åº“å­˜"
            )

            # æ·»åŠ æŠ˜çº¿å›¾
            fig_combined.add_scatter(
                x=combined_data["å¤©æ•°åŒºé—´"],
                y=combined_data["MSKUæ•°é‡"],
                mode="lines+markers",
                name="MSKUæ•°é‡",
                yaxis="y2",
                line=dict(color="#C73E1D", width=3),
                marker=dict(color="#C73E1D", size=6),
                text=combined_data["MSKUæ•°é‡"],
                textposition="top center"
            )

            # 2.5 å›¾è¡¨æ ·å¼ä¼˜åŒ–ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šå°†orientation="horizontal"æ”¹ä¸ºorientation="h"ï¼‰
            fig_combined.update_layout(
                yaxis=dict(
                    title=dict(
                        text="æ€»æ»é”€åº“å­˜",
                        font=dict(color="#F18F01")
                    ),
                    tickfont=dict(color="#F18F01"),
                    showgrid=True,
                    gridcolor="#eee"
                ),
                yaxis2=dict(
                    title=dict(
                        text="MSKUæ•°é‡",
                        font=dict(color="#C73E1D")
                    ),
                    tickfont=dict(color="#C73E1D"),
                    showgrid=False,
                    overlaying="y",
                    side="right"
                ),
                xaxis=dict(
                    title="åº“å­˜æ¶ˆè€—å¤©æ•°åŒºé—´ï¼ˆå¤©ï¼‰",
                    tickangle=45,
                    tickfont=dict(size=10)
                ),
                showlegend=True,
                # ä¿®å¤ï¼šå°†"horizontal"æ”¹ä¸ºç®€å†™"h"
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
                plot_bgcolor="#f8f9fa",
                margin=dict(t=50, b=80, l=20, r=20)
            )

            # 2.6 æ•°å€¼æ˜¾ç¤ºä¼˜åŒ–
            fig_combined.update_traces(
                selector=dict(type="bar"),
                texttemplate="%.2f",
                textposition="outside",
                textfont=dict(size=10, weight="bold")
            )
            fig_combined.update_traces(
                selector=dict(type="scatter"),
                texttemplate="%d",
                textfont=dict(size=10, weight="bold")
            )

            st.plotly_chart(fig_combined, use_container_width=True)

            # äº§å“åˆ—è¡¨ä¸ä¸‹è½½åŠŸèƒ½
            st.subheader(f"{selected_store} äº§å“åˆ—è¡¨")

            # æ ¸å¿ƒä¿®æ”¹1ï¼šåœ¨display_columnsä¸­æ–°å¢8ä¸ªåˆ—ï¼ˆ4ä¸ªç³»æ•°+4ä¸ªè°ƒæ•´åæ—¥å‡ï¼‰
            display_columns = [
                "åº—é“º", "MSKU", "å“å", "è®°å½•æ—¶é—´",
                # åŸºç¡€æ—¥å‡åˆ—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
                "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’å…¥ï¼‰
                "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
                "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
                # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
                "FBA+AWD+åœ¨é€”åº“å­˜", "æœ¬åœ°å¯ç”¨", "å…¨éƒ¨æ€»åº“å­˜", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´",
                "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ", "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡", "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡",
                "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
                "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°", "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
            ]

            render_product_detail_table(
                store_current_data,
                prev_data[prev_data["åº—é“º"] == selected_store] if (
                        prev_data is not None and not prev_data.empty) else None,
                page=st.session_state.current_page,
                page_size=30,
                table_id=f"store_{selected_store}"
            )

            if not store_current_data.empty:
                # æ ¸å¿ƒä¿®æ”¹2ï¼šç­›é€‰ä¸‹è½½æ•°æ®æ—¶åŒ…å«æ–°å¢çš„8ä¸ªåˆ—ï¼ˆè‡ªåŠ¨è¿‡æ»¤ä¸å­˜åœ¨çš„åˆ—ï¼‰
                existing_cols = [col for col in display_columns if col in store_current_data.columns]
                download_data = store_current_data[existing_cols].copy()

                # æ—¥æœŸæ ¼å¼åŒ–ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
                date_cols = ["è®°å½•æ—¶é—´", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"]
                for col in date_cols:
                    if col in download_data.columns:
                        download_data[col] = pd.to_datetime(download_data[col]).dt.strftime("%Y-%m-%d")

                # ç”ŸæˆCSVå¹¶æä¾›ä¸‹è½½ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
                csv = download_data.to_csv(index=False, encoding='utf-8-sig')
                file_name = f"{selected_store}_äº§å“åˆ—è¡¨_{today.strftime('%Y%m%d')}.csv"

                st.download_button(
                    label="ä¸‹è½½ç­›é€‰ç»“æœ (CSV)",
                    data=csv,
                    file_name=file_name,
                    mime="text/csv",
                    key=f"download_{selected_store}"
                )
    else:
        st.warning("æ— åº—é“ºæ•°æ®å¯åˆ†æ")

    # å•ä¸ªMSKUåˆ†æ
    st.subheader("å•ä¸ªMSKUåˆ†æ")
    if current_data is not None and not current_data.empty:
        msku_list = sorted(current_data["MSKU"].unique())
        # æ·»åŠ MSKUæŸ¥è¯¢è¾“å…¥æ¡†
        col1, col2 = st.columns([3, 1])
        with col1:
            msku_query = st.text_input(
                "è¾“å…¥MSKUæŸ¥è¯¢",
                placeholder="ç²˜è´´MSKUä»£ç å¿«é€ŸæŸ¥è¯¢...",
                key="msku_query"
            )
        # æ ¹æ®æŸ¥è¯¢å†…å®¹è¿‡æ»¤ä¸‹æ‹‰é€‰é¡¹
        if msku_query:
            filtered_mskus = [msku for msku in msku_list if msku_query.strip().lower() in msku.lower()]
            if not filtered_mskus:
                st.warning(f"æœªæ‰¾åˆ°åŒ…å« '{msku_query}' çš„MSKUï¼Œè¯·æ£€æŸ¥è¾“å…¥")
                filtered_mskus = msku_list  # æœªæ‰¾åˆ°æ—¶æ˜¾ç¤ºå…¨éƒ¨
        else:
            filtered_mskus = msku_list
        # ä¸‹æ‹‰é€‰æ‹©æ¡†ï¼ˆä¼šæ ¹æ®æŸ¥è¯¢å†…å®¹åŠ¨æ€è¿‡æ»¤ï¼‰
        with col2:
            selected_msku = st.selectbox("æˆ–ä»åˆ—è¡¨é€‰æ‹©", options=filtered_mskus, key="msku_select")
        if selected_msku:
            product_data = current_data[current_data["MSKU"] == selected_msku]
            product_info = product_data.iloc[0].to_dict()
            # äº§å“ä¿¡æ¯è¡¨æ ¼
            st.subheader("äº§å“åŸºæœ¬ä¿¡æ¯")
            # æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨display_colsä¸­æ–°å¢8ä¸ªåˆ—ï¼ˆ4ä¸ªç³»æ•°+4ä¸ªè°ƒæ•´åæ—¥å‡ï¼‰
            display_cols = [
                "MSKU", "å“å", "åº—é“º",
                # åŸºç¡€æ—¥å‡åˆ—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
                "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’å…¥ï¼‰
                "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
                "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
                # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
                "FBA+AWD+åœ¨é€”åº“å­˜", "æœ¬åœ°å¯ç”¨", "å…¨éƒ¨æ€»åº“å­˜", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ",
                "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡", "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
                "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°", "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
            ]
            # åˆ›å»ºä¿¡æ¯è¡¨æ ¼ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œè‡ªåŠ¨é€‚é…æ–°å¢åˆ—ï¼‰
            info_df = product_data[display_cols].copy()
            # æ ¼å¼åŒ–æ—¥æœŸï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            date_cols = ["é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"]
            for col in date_cols:
                if col in info_df.columns:
                    info_df[col] = pd.to_datetime(info_df[col]).dt.strftime("%Y-%m-%d")
            # æ·»åŠ çŠ¶æ€é¢œè‰²ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if "çŠ¶æ€åˆ¤æ–­" in info_df.columns:
                info_df["çŠ¶æ€åˆ¤æ–­"] = info_df["çŠ¶æ€åˆ¤æ–­"].apply(
                    lambda x: f"<span style='color:{STATUS_COLORS[x]}; font-weight:bold;'>{x}</span>"
                )
            # æ–°å¢ï¼šï¼ˆå¯é€‰ï¼‰æ ¼å¼åŒ–ç³»æ•°åˆ—æ˜¾ç¤ºï¼ˆä¿ç•™2ä½å°æ•°ï¼Œå¢å¼ºå¯è¯»æ€§ï¼‰
            coefficient_cols = [
                "10æœˆ15-31æ—¥ç³»æ•°", "11æœˆ1-15æ—¥ç³»æ•°",
                "11æœˆ16-30æ—¥ç³»æ•°", "12æœˆ1-31æ—¥ç³»æ•°"
            ]
            for col in coefficient_cols:
                if col in info_df.columns:
                    info_df[col] = info_df[col].round(2)  # ç³»æ•°å›ºå®šä¸º2ä½å°æ•°
            # æ˜¾ç¤ºè¡¨æ ¼ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            st.markdown(info_df.to_html(escape=False, index=False), unsafe_allow_html=True)
            # åº“å­˜é¢„æµ‹å›¾è¡¨ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œå›¾è¡¨å·²åŸºäºåˆ†é˜¶æ®µæ—¥å‡è®¡ç®—ï¼‰
            forecast_fig = render_stock_forecast_chart(product_data, selected_msku)
            st.plotly_chart(forecast_fig, use_container_width=True)
    else:
        st.warning("æ— äº§å“æ•°æ®å¯åˆ†æ")

    # ------------------------------
    # ç¬¬äºŒéƒ¨åˆ†ï¼šè¶‹åŠ¿ä¸å˜åŒ–åˆ†æ
    # ------------------------------
    st.header("2 è¿‘ä¸€ä¸ªæœˆçš„è¶‹åŠ¿ä¸å˜åŒ–åˆ†æ")

    # 2.1 ä¸‰å‘¨çŠ¶æ€å˜åŒ–è¶‹åŠ¿ï¼ˆæŸ±çŠ¶å›¾ç‰ˆæœ¬ï¼‰
    st.subheader("2.1 è¿‘ä¸€ä¸ªæœˆçŠ¶æ€å˜åŒ–è¶‹åŠ¿")
    trend_fig = render_four_week_status_chart(df, all_dates)
    st.plotly_chart(trend_fig, use_container_width=True)

    # 2.2 åº—é“ºå‘¨å˜åŒ–æƒ…å†µ
    st.subheader("2.2 åº—é“ºå‘¨å˜åŒ–æƒ…å†µ")
    render_store_weekly_changes(df, all_dates)

    # åº—é“ºè¶‹åŠ¿å›¾è¡¨ï¼ˆåˆ†ä¸¤åˆ—æ˜¾ç¤ºï¼‰
    st.subheader("2.3 åº—é“ºçŠ¶æ€è¶‹åŠ¿å›¾")
    render_store_trend_charts(df, all_dates)

    # 2.4 åº—é“ºä¸çŠ¶æ€å˜åŒ–è”åˆåˆ†æ
    st.subheader("2.4 åº—é“ºä¸çŠ¶æ€å˜åŒ–è”åˆåˆ†æ")
    if df is not None and not df.empty:
        # åº—é“ºç­›é€‰å™¨ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        all_stores = sorted(df["åº—é“º"].unique())
        selected_analysis_store = st.selectbox(
            "é€‰æ‹©åº—é“ºè¿›è¡Œè”åˆåˆ†æ",
            options=["å…¨éƒ¨"] + all_stores
        )

        # ç­›é€‰æ•°æ®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        analysis_data = df.copy()
        if selected_analysis_store != "å…¨éƒ¨":
            analysis_data = analysis_data[analysis_data["åº—é“º"] == selected_analysis_store]

        # æŒ‰åº—é“ºå’ŒMSKUè¿›è¡Œæ’åºï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        analysis_data = analysis_data.sort_values(by=["åº—é“º", "MSKU"])

        # æ ¸å¿ƒä¿®æ”¹1ï¼šåœ¨display_columnsä¸­æ–°å¢8ä¸ªåˆ—ï¼ˆ4ä¸ªç³»æ•°+4ä¸ªè°ƒæ•´åæ—¥å‡ï¼‰
        display_columns = [
            "MSKU", "å“å", "åº—é“º",
            # åŸºç¡€æ—¥å‡åˆ—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
            "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
            # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’å…¥ï¼‰
            "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
            "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
            "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
            "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
            # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
            "FBA+AWD+åœ¨é€”åº“å­˜", "æœ¬åœ°å¯ç”¨",
            "å…¨éƒ¨æ€»åº“å­˜", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´",
            "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ", "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡",
            "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
            "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°",
            "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
        ]

        # å¯é€‰ï¼šæ£€æŸ¥å¹¶æ·»åŠ æ•°æ®ä¸­å®é™…å­˜åœ¨çš„ç±»ä¼¼åˆ—ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        # if "ä¸ŠæœŸçŠ¶æ€" in analysis_data.columns:
        #     display_columns.insert(5, "ä¸ŠæœŸçŠ¶æ€")

        # æ˜¾ç¤ºçŠ¶æ€å˜åŒ–è¡¨ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œè‡ªåŠ¨é€‚é…æ–°å¢åˆ—ï¼‰
        render_status_change_table(
            analysis_data,
            page=st.session_state.current_status_page,
            page_size=30
        )

        # æ·»åŠ ä¸‹è½½æŒ‰é’®ï¼ˆä¸‹è½½ç­›é€‰åçš„æ‰€æœ‰æ•°æ®ï¼‰
        if not analysis_data.empty:
            # æ ¸å¿ƒä¿®æ”¹2ï¼šåœ¨expected_columnsä¸­æ–°å¢8ä¸ªåˆ—ï¼ˆä¸display_columnsåŒæ­¥ï¼‰
            expected_columns = [
                "MSKU", "å“å", "åº—é“º", "è®°å½•æ—¶é—´",
                # åŸºç¡€æ—¥å‡åˆ—
                "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡
                "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
                "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
                # åŸæœ‰å…¶ä»–åˆ—
                "FBA+AWD+åœ¨é€”åº“å­˜", "æœ¬åœ°å¯ç”¨",
                "å…¨éƒ¨æ€»åº“å­˜", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´",
                "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ", "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡",
                "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
                "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°",
                "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
            ]

            # 2. æ£€æŸ¥æ•°æ®ä¸­å®é™…å­˜åœ¨çš„åˆ—ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            filtered_data = analysis_data.copy()
            actual_columns = filtered_data.columns.tolist()

            # 3. æ‰¾å‡ºå­˜åœ¨çš„æœ‰æ•ˆåˆ—å’Œç¼ºå¤±çš„åˆ—ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œè‡ªåŠ¨åŒ…å«æ–°å¢åˆ—ï¼‰
            valid_columns = [col for col in expected_columns if col in actual_columns]
            missing_columns = [col for col in expected_columns if col not in actual_columns]

            # 4. æ˜¾ç¤ºç¼ºå¤±åˆ—çš„è­¦å‘Šä¿¡æ¯ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if missing_columns:
                st.warning(f"æ•°æ®ä¸­ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼Œå·²è‡ªåŠ¨è·³è¿‡ï¼š{', '.join(missing_columns)}")

            # 5. ç¡®ä¿è‡³å°‘æœ‰ä¸€åˆ—å¯ç”¨äºä¸‹è½½ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if valid_columns:
                download_data = filtered_data[valid_columns]
            else:
                st.error("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åˆ—ç”¨äºç”Ÿæˆä¸‹è½½æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®")
                download_data = pd.DataFrame()  # åˆ›å»ºç©ºDataFrameé¿å…åç»­é”™è¯¯

            # æ ¼å¼åŒ–æ—¥æœŸåˆ—ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if "è®°å½•æ—¶é—´" in download_data.columns:
                download_data["è®°å½•æ—¶é—´"] = pd.to_datetime(download_data["è®°å½•æ—¶é—´"]).dt.strftime("%Y-%m-%d")

            # ç”ŸæˆCSVï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            csv = download_data.to_csv(index=False, encoding='utf-8-sig')

            # æ„å»ºæ–‡ä»¶åï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            store_part = selected_analysis_store if selected_analysis_store != "å…¨éƒ¨" else "æ‰€æœ‰åº—é“º"
            file_name = f"åº—é“ºçŠ¶æ€å˜åŒ–è”åˆåˆ†æ_{store_part}.csv"

            # ä¸‹è½½æŒ‰é’®ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            st.download_button(
                label="ä¸‹è½½ç­›é€‰ç»“æœ (CSV)",
                data=csv,
                file_name=file_name,
                mime="text/csv",
                key="download_status_change_analysis"
            )
    else:
        st.warning("æ— æ•°æ®å¯è¿›è¡Œè”åˆåˆ†æ")

    # 2.5 å•ä¸ªäº§å“è¯¦ç»†åˆ†æ
    st.subheader("2.5 å•ä¸ªäº§å“è¯¦ç»†åˆ†æ")
    if df is not None and not df.empty:
        # è·å–æ‰€æœ‰MSKUå¹¶æ’åºï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        all_mskus = sorted(df["MSKU"].unique())

        # æ·»åŠ æœç´¢æ¡†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        search_term = st.text_input(
            "æœç´¢äº§å“ï¼ˆMSKUæˆ–å“åï¼‰",
            placeholder="è¾“å…¥å…³é”®è¯æœç´¢..."
        )

        # æ ¹æ®æœç´¢è¯è¿‡æ»¤äº§å“ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        if search_term:
            search_lower = search_term.lower()
            filtered_mskus = []
            for msku in all_mskus:
                product_names = df[df["MSKU"] == msku]["å“å"].unique()
                if (search_lower in str(msku).lower() or
                        any(search_lower in str(name).lower() for name in product_names)):
                    filtered_mskus.append(msku)
            if not filtered_mskus:
                st.info(f"æ²¡æœ‰æ‰¾åˆ°åŒ…å« '{search_term}' çš„äº§å“ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯")
                filtered_mskus = all_mskus
        else:
            filtered_mskus = all_mskus

        # äº§å“ç­›é€‰å™¨ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        selected_analysis_msku = st.selectbox(
            "é€‰æ‹©äº§å“è¿›è¡Œè¯¦ç»†åˆ†æ",
            options=filtered_mskus
        )

        if selected_analysis_msku:
            # è·å–è¯¥äº§å“çš„æ‰€æœ‰è®°å½•ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            product_history_data = df[df["MSKU"] == selected_analysis_msku].sort_values("è®°å½•æ—¶é—´", ascending=False)

            # æ ¸å¿ƒä¿®æ”¹ï¼šåœ¨display_colsä¸­æ–°å¢8ä¸ªåˆ—ï¼ˆ4ä¸ªç³»æ•°+4ä¸ªè°ƒæ•´åæ—¥å‡ï¼‰
            display_cols = [
                "MSKU", "å“å", "åº—é“º", "è®°å½•æ—¶é—´",
                # åŸºç¡€æ—¥å‡åˆ—ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
                "æ—¥å‡", "7å¤©æ—¥å‡", "14å¤©æ—¥å‡", "28å¤©æ—¥å‡",
                # æ–°å¢ï¼šå››ä¸ªæ—¶é—´æ®µçš„ç³»æ•°+è°ƒæ•´åæ—¥å‡ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’å…¥ï¼‰
                "10æœˆ15-31æ—¥ç³»æ•°", "10æœˆ15-31æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ1-15æ—¥ç³»æ•°", "11æœˆ1-15æ—¥è°ƒæ•´åæ—¥å‡",
                "11æœˆ16-30æ—¥ç³»æ•°", "11æœˆ16-30æ—¥è°ƒæ•´åæ—¥å‡",
                "12æœˆ1-31æ—¥ç³»æ•°", "12æœˆ1-31æ—¥è°ƒæ•´åæ—¥å‡",
                # åŸæœ‰å…¶ä»–åˆ—ï¼ˆä¿æŒä¸å˜ï¼‰
                "FBA+AWD+åœ¨é€”åº“å­˜", "æœ¬åœ°å¯ç”¨", "å…¨éƒ¨æ€»åº“å­˜", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ",
                "çŠ¶æ€åˆ¤æ–­", "æ¸…åº“å­˜çš„ç›®æ ‡æ—¥å‡", "FBA+AWD+åœ¨é€”æ»é”€æ•°é‡", "æœ¬åœ°æ»é”€æ•°é‡", "æ€»æ»é”€åº“å­˜",
                "é¢„è®¡æ€»åº“å­˜éœ€è¦æ¶ˆè€—å¤©æ•°", "é¢„è®¡ç”¨å®Œæ—¶é—´æ¯”ç›®æ ‡æ—¶é—´å¤šå‡ºæ¥çš„å¤©æ•°", "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"
            ]

            # ç­›é€‰å¹¶æ ¼å¼åŒ–è¡¨æ ¼æ•°æ®ï¼ˆä¿æŒåŸé€»è¾‘ï¼Œè‡ªåŠ¨é€‚é…æ–°å¢åˆ—ï¼‰
            table_data = product_history_data[display_cols].copy()

            # æ ¼å¼åŒ–æ—¥æœŸåˆ—ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            date_cols = ["è®°å½•æ—¶é—´", "é¢„è®¡FBA+AWD+åœ¨é€”ç”¨å®Œæ—¶é—´", "é¢„è®¡æ€»åº“å­˜ç”¨å®Œ"]
            for col in date_cols:
                if col in table_data.columns:
                    table_data[col] = pd.to_datetime(table_data[col]).dt.strftime("%Y-%m-%d")

            # æ·»åŠ çŠ¶æ€é¢œè‰²ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if "çŠ¶æ€åˆ¤æ–­" in table_data.columns:
                table_data["çŠ¶æ€åˆ¤æ–­"] = table_data["çŠ¶æ€åˆ¤æ–­"].apply(
                    lambda x: f"<span style='color:{STATUS_COLORS[x]}; font-weight:bold;'>{x}</span>"
                )

            # æ·»åŠ ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–é¢œè‰²ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            if "ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–" in table_data.columns:
                def color_status_change(x):
                    if x == "æ”¹å–„":
                        return f"<span style='color:#2E8B57; font-weight:bold;'>{x}</span>"
                    elif x == "æ¶åŒ–":
                        return f"<span style='color:#DC143C; font-weight:bold;'>{x}</span>"
                    else:  # ç»´æŒä¸å˜
                        return f"<span style='color:#000000; font-weight:bold;'>{x}</span>"

                table_data["ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"] = table_data["ç¯æ¯”ä¸Šå‘¨åº“å­˜æ»é”€æƒ…å†µå˜åŒ–"].apply(
                    color_status_change)

            # æ˜¾ç¤ºäº§å“å†å²æ•°æ®è¡¨æ ¼ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
            st.subheader("äº§å“å†å²æ•°æ®")
            st.markdown(table_data.to_html(escape=False, index=False), unsafe_allow_html=True)

            # ç”Ÿæˆåº“å­˜é¢„æµ‹å¯¹æ¯”å›¾ï¼ˆå·²åœ¨ä¹‹å‰ä¿®æ”¹ï¼Œå«åˆ†é˜¶æ®µç³»æ•°ï¼‰
            forecast_chart = render_product_detail_chart(df, selected_analysis_msku)
            st.plotly_chart(forecast_chart, use_container_width=True)
    else:
        st.warning("æ— äº§å“æ•°æ®å¯è¿›è¡Œè¯¦ç»†åˆ†æ")


if __name__ == "__main__":
    main()
